{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (6.2.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.13)\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-pb6lpjkp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-pb6lpjkp\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (6.2.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.0.0.post200)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.15.2a0+072ec57)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless\n",
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.v2 import AugMix\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from clip import load, tokenize\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import boto3\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MEMO_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TPT_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "imageNetA = True\n",
    "naug = 64\n",
    "top = 0.1\n",
    "niter = 1\n",
    "no_backwards = True\n",
    "testSingleModels = True\n",
    "\n",
    "# set the seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Class names mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes = [\"tench\", \"goldfish\", \"great white shark\", \"tiger shark\", \"hammerhead shark\", \"electric ray\", \"stingray\", \"rooster\", \"hen\", \"ostrich\", \"brambling\", \"goldfinch\", \"house finch\", \"junco\", \"indigo bunting\", \"American robin\", \"bulbul\", \"jay\", \"magpie\", \"chickadee\", \"American dipper\", \"kite (bird of prey)\", \"bald eagle\", \"vulture\", \"great grey owl\", \"fire salamander\", \"smooth newt\", \"newt\", \"spotted salamander\", \"axolotl\", \"American bullfrog\", \"tree frog\", \"tailed frog\", \"loggerhead sea turtle\", \"leatherback sea turtle\", \"mud turtle\", \"terrapin\", \"box turtle\", \"banded gecko\", \"green iguana\", \"Carolina anole\", \"desert grassland whiptail lizard\", \"agama\", \"frilled-necked lizard\", \"alligator lizard\", \"Gila monster\", \"European green lizard\", \"chameleon\", \"Komodo dragon\", \"Nile crocodile\", \"American alligator\", \"triceratops\", \"worm snake\", \"ring-necked snake\", \"eastern hog-nosed snake\", \"smooth green snake\", \"kingsnake\", \"garter snake\", \"water snake\", \"vine snake\", \"night snake\", \"boa constrictor\", \"African rock python\", \"Indian cobra\", \"green mamba\", \"sea snake\", \"Saharan horned viper\", \"eastern diamondback rattlesnake\", \"sidewinder rattlesnake\", \"trilobite\", \"harvestman\", \"scorpion\", \"yellow garden spider\", \"barn spider\", \"European garden spider\", \"southern black widow\", \"tarantula\", \"wolf spider\", \"tick\", \"centipede\", \"black grouse\", \"ptarmigan\", \"ruffed grouse\", \"prairie grouse\", \"peafowl\", \"quail\", \"partridge\", \"african grey parrot\", \"macaw\", \"sulphur-crested cockatoo\", \"lorikeet\", \"coucal\", \"bee eater\", \"hornbill\", \"hummingbird\", \"jacamar\", \"toucan\", \"duck\", \"red-breasted merganser\", \"goose\", \"black swan\", \"tusker\", \"echidna\", \"platypus\", \"wallaby\", \"koala\", \"wombat\", \"jellyfish\", \"sea anemone\", \"brain coral\", \"flatworm\", \"nematode\", \"conch\", \"snail\", \"slug\", \"sea slug\", \"chiton\", \"chambered nautilus\", \"Dungeness crab\", \"rock crab\", \"fiddler crab\", \"red king crab\", \"American lobster\", \"spiny lobster\", \"crayfish\", \"hermit crab\", \"isopod\", \"white stork\", \"black stork\", \"spoonbill\", \"flamingo\", \"little blue heron\", \"great egret\", \"bittern bird\", \"crane bird\", \"limpkin\", \"common gallinule\", \"American coot\", \"bustard\", \"ruddy turnstone\", \"dunlin\", \"common redshank\", \"dowitcher\", \"oystercatcher\", \"pelican\", \"king penguin\", \"albatross\", \"grey whale\", \"killer whale\", \"dugong\", \"sea lion\", \"Chihuahua\", \"Japanese Chin\", \"Maltese\", \"Pekingese\", \"Shih Tzu\", \"King Charles Spaniel\", \"Papillon\", \"toy terrier\", \"Rhodesian Ridgeback\", \"Afghan Hound\", \"Basset Hound\", \"Beagle\", \"Bloodhound\", \"Bluetick Coonhound\", \"Black and Tan Coonhound\", \"Treeing Walker Coonhound\", \"English foxhound\", \"Redbone Coonhound\", \"borzoi\", \"Irish Wolfhound\", \"Italian Greyhound\", \"Whippet\", \"Ibizan Hound\", \"Norwegian Elkhound\", \"Otterhound\", \"Saluki\", \"Scottish Deerhound\", \"Weimaraner\", \"Staffordshire Bull Terrier\", \"American Staffordshire Terrier\", \"Bedlington Terrier\", \"Border Terrier\", \"Kerry Blue Terrier\", \"Irish Terrier\", \"Norfolk Terrier\", \"Norwich Terrier\", \"Yorkshire Terrier\", \"Wire Fox Terrier\", \"Lakeland Terrier\", \"Sealyham Terrier\", \"Airedale Terrier\", \"Cairn Terrier\", \"Australian Terrier\", \"Dandie Dinmont Terrier\", \"Boston Terrier\", \"Miniature Schnauzer\", \"Giant Schnauzer\", \"Standard Schnauzer\", \"Scottish Terrier\", \"Tibetan Terrier\", \"Australian Silky Terrier\", \"Soft-coated Wheaten Terrier\", \"West Highland White Terrier\", \"Lhasa Apso\", \"Flat-Coated Retriever\", \"Curly-coated Retriever\", \"Golden Retriever\", \"Labrador Retriever\", \"Chesapeake Bay Retriever\", \"German Shorthaired Pointer\", \"Vizsla\", \"English Setter\", \"Irish Setter\", \"Gordon Setter\", \"Brittany dog\", \"Clumber Spaniel\", \"English Springer Spaniel\", \"Welsh Springer Spaniel\", \"Cocker Spaniel\", \"Sussex Spaniel\", \"Irish Water Spaniel\", \"Kuvasz\", \"Schipperke\", \"Groenendael dog\", \"Malinois\", \"Briard\", \"Australian Kelpie\", \"Komondor\", \"Old English Sheepdog\", \"Shetland Sheepdog\", \"collie\", \"Border Collie\", \"Bouvier des Flandres dog\", \"Rottweiler\", \"German Shepherd Dog\", \"Dobermann\", \"Miniature Pinscher\", \"Greater Swiss Mountain Dog\", \"Bernese Mountain Dog\", \"Appenzeller Sennenhund\", \"Entlebucher Sennenhund\", \"Boxer\", \"Bullmastiff\", \"Tibetan Mastiff\", \"French Bulldog\", \"Great Dane\", \"St. Bernard\", \"husky\", \"Alaskan Malamute\", \"Siberian Husky\", \"Dalmatian\", \"Affenpinscher\", \"Basenji\", \"pug\", \"Leonberger\", \"Newfoundland dog\", \"Great Pyrenees dog\", \"Samoyed\", \"Pomeranian\", \"Chow Chow\", \"Keeshond\", \"brussels griffon\", \"Pembroke Welsh Corgi\", \"Cardigan Welsh Corgi\", \"Toy Poodle\", \"Miniature Poodle\", \"Standard Poodle\", \"Mexican hairless dog (xoloitzcuintli)\", \"grey wolf\", \"Alaskan tundra wolf\", \"red wolf or maned wolf\", \"coyote\", \"dingo\", \"dhole\", \"African wild dog\", \"hyena\", \"red fox\", \"kit fox\", \"Arctic fox\", \"grey fox\", \"tabby cat\", \"tiger cat\", \"Persian cat\", \"Siamese cat\", \"Egyptian Mau\", \"cougar\", \"lynx\", \"leopard\", \"snow leopard\", \"jaguar\", \"lion\", \"tiger\", \"cheetah\", \"brown bear\", \"American black bear\", \"polar bear\", \"sloth bear\", \"mongoose\", \"meerkat\", \"tiger beetle\", \"ladybug\", \"ground beetle\", \"longhorn beetle\", \"leaf beetle\", \"dung beetle\", \"rhinoceros beetle\", \"weevil\", \"fly\", \"bee\", \"ant\", \"grasshopper\", \"cricket insect\", \"stick insect\", \"cockroach\", \"praying mantis\", \"cicada\", \"leafhopper\", \"lacewing\", \"dragonfly\", \"damselfly\", \"red admiral butterfly\", \"ringlet butterfly\", \"monarch butterfly\", \"small white butterfly\", \"sulphur butterfly\", \"gossamer-winged butterfly\", \"starfish\", \"sea urchin\", \"sea cucumber\", \"cottontail rabbit\", \"hare\", \"Angora rabbit\", \"hamster\", \"porcupine\", \"fox squirrel\", \"marmot\", \"beaver\", \"guinea pig\", \"common sorrel horse\", \"zebra\", \"pig\", \"wild boar\", \"warthog\", \"hippopotamus\", \"ox\", \"water buffalo\", \"bison\", \"ram (adult male sheep)\", \"bighorn sheep\", \"Alpine ibex\", \"hartebeest\", \"impala (antelope)\", \"gazelle\", \"arabian camel\", \"llama\", \"weasel\", \"mink\", \"European polecat\", \"black-footed ferret\", \"otter\", \"skunk\", \"badger\", \"armadillo\", \"three-toed sloth\", \"orangutan\", \"gorilla\", \"chimpanzee\", \"gibbon\", \"siamang\", \"guenon\", \"patas monkey\", \"baboon\", \"macaque\", \"langur\", \"black-and-white colobus\", \"proboscis monkey\", \"marmoset\", \"white-headed capuchin\", \"howler monkey\", \"titi monkey\", \"Geoffroy's spider monkey\", \"common squirrel monkey\", \"ring-tailed lemur\", \"indri\", \"Asian elephant\", \"African bush elephant\", \"red panda\", \"giant panda\", \"snoek fish\", \"eel\", \"silver salmon\", \"rock beauty fish\", \"clownfish\", \"sturgeon\", \"gar fish\", \"lionfish\", \"pufferfish\", \"abacus\", \"abaya\", \"academic gown\", \"accordion\", \"acoustic guitar\", \"aircraft carrier\", \"airliner\", \"airship\", \"altar\", \"ambulance\", \"amphibious vehicle\", \"analog clock\", \"apiary\", \"apron\", \"trash can\", \"assault rifle\", \"backpack\", \"bakery\", \"balance beam\", \"balloon\", \"ballpoint pen\", \"Band-Aid\", \"banjo\", \"baluster / handrail\", \"barbell\", \"barber chair\", \"barbershop\", \"barn\", \"barometer\", \"barrel\", \"wheelbarrow\", \"baseball\", \"basketball\", \"bassinet\", \"bassoon\", \"swimming cap\", \"bath towel\", \"bathtub\", \"station wagon\", \"lighthouse\", \"beaker\", \"military hat (bearskin or shako)\", \"beer bottle\", \"beer glass\", \"bell tower\", \"baby bib\", \"tandem bicycle\", \"bikini\", \"ring binder\", \"binoculars\", \"birdhouse\", \"boathouse\", \"bobsleigh\", \"bolo tie\", \"poke bonnet\", \"bookcase\", \"bookstore\", \"bottle cap\", \"hunting bow\", \"bow tie\", \"brass memorial plaque\", \"bra\", \"breakwater\", \"breastplate\", \"broom\", \"bucket\", \"buckle\", \"bulletproof vest\", \"high-speed train\", \"butcher shop\", \"taxicab\", \"cauldron\", \"candle\", \"cannon\", \"canoe\", \"can opener\", \"cardigan\", \"car mirror\", \"carousel\", \"tool kit\", \"cardboard box / carton\", \"car wheel\", \"automated teller machine\", \"cassette\", \"cassette player\", \"castle\", \"catamaran\", \"CD player\", \"cello\", \"mobile phone\", \"chain\", \"chain-link fence\", \"chain mail\", \"chainsaw\", \"storage chest\", \"chiffonier\", \"bell or wind chime\", \"china cabinet\", \"Christmas stocking\", \"church\", \"movie theater\", \"cleaver\", \"cliff dwelling\", \"cloak\", \"clogs\", \"cocktail shaker\", \"coffee mug\", \"coffeemaker\", \"spiral or coil\", \"combination lock\", \"computer keyboard\", \"candy store\", \"container ship\", \"convertible\", \"corkscrew\", \"cornet\", \"cowboy boot\", \"cowboy hat\", \"cradle\", \"construction crane\", \"crash helmet\", \"crate\", \"infant bed\", \"Crock Pot\", \"croquet ball\", \"crutch\", \"cuirass\", \"dam\", \"desk\", \"desktop computer\", \"rotary dial telephone\", \"diaper\", \"digital clock\", \"digital watch\", \"dining table\", \"dishcloth\", \"dishwasher\", \"disc brake\", \"dock\", \"dog sled\", \"dome\", \"doormat\", \"drilling rig\", \"drum\", \"drumstick\", \"dumbbell\", \"Dutch oven\", \"electric fan\", \"electric guitar\", \"electric locomotive\", \"entertainment center\", \"envelope\", \"espresso machine\", \"face powder\", \"feather boa\", \"filing cabinet\", \"fireboat\", \"fire truck\", \"fire screen\", \"flagpole\", \"flute\", \"folding chair\", \"football helmet\", \"forklift\", \"fountain\", \"fountain pen\", \"four-poster bed\", \"freight car\", \"French horn\", \"frying pan\", \"fur coat\", \"garbage truck\", \"gas mask or respirator\", \"gas pump\", \"goblet\", \"go-kart\", \"golf ball\", \"golf cart\", \"gondola\", \"gong\", \"gown\", \"grand piano\", \"greenhouse\", \"radiator grille\", \"grocery store\", \"guillotine\", \"hair clip\", \"hair spray\", \"half-track\", \"hammer\", \"hamper\", \"hair dryer\", \"hand-held computer\", \"handkerchief\", \"hard disk drive\", \"harmonica\", \"harp\", \"combine harvester\", \"hatchet\", \"holster\", \"home theater\", \"honeycomb\", \"hook\", \"hoop skirt\", \"gymnastic horizontal bar\", \"horse-drawn vehicle\", \"hourglass\", \"iPod\", \"clothes iron\", \"carved pumpkin\", \"jeans\", \"jeep\", \"T-shirt\", \"jigsaw puzzle\", \"rickshaw\", \"joystick\", \"kimono\", \"knee pad\", \"knot\", \"lab coat\", \"ladle\", \"lampshade\", \"laptop computer\", \"lawn mower\", \"lens cap\", \"letter opener\", \"library\", \"lifeboat\", \"lighter\", \"limousine\", \"ocean liner\", \"lipstick\", \"slip-on shoe\", \"lotion\", \"music speaker\", \"loupe magnifying glass\", \"sawmill\", \"magnetic compass\", \"messenger bag\", \"mailbox\", \"tights\", \"one-piece bathing suit\", \"manhole cover\", \"maraca\", \"marimba\", \"mask\", \"matchstick\", \"maypole\", \"maze\", \"measuring cup\", \"medicine cabinet\", \"megalith\", \"microphone\", \"microwave oven\", \"military uniform\", \"milk can\", \"minibus\", \"miniskirt\", \"minivan\", \"missile\", \"mitten\", \"mixing bowl\", \"mobile home\", \"ford model t\", \"modem\", \"monastery\", \"monitor\", \"moped\", \"mortar and pestle\", \"graduation cap\", \"mosque\", \"mosquito net\", \"vespa\", \"mountain bike\", \"tent\", \"computer mouse\", \"mousetrap\", \"moving van\", \"muzzle\", \"metal nail\", \"neck brace\", \"necklace\", \"baby pacifier\", \"notebook computer\", \"obelisk\", \"oboe\", \"ocarina\", \"odometer\", \"oil filter\", \"pipe organ\", \"oscilloscope\", \"overskirt\", \"bullock cart\", \"oxygen mask\", \"product packet / packaging\", \"paddle\", \"paddle wheel\", \"padlock\", \"paintbrush\", \"pajamas\", \"palace\", \"pan flute\", \"paper towel\", \"parachute\", \"parallel bars\", \"park bench\", \"parking meter\", \"railroad car\", \"patio\", \"payphone\", \"pedestal\", \"pencil case\", \"pencil sharpener\", \"perfume\", \"Petri dish\", \"photocopier\", \"plectrum\", \"Pickelhaube\", \"picket fence\", \"pickup truck\", \"pier\", \"piggy bank\", \"pill bottle\", \"pillow\", \"ping-pong ball\", \"pinwheel\", \"pirate ship\", \"drink pitcher\", \"block plane\", \"planetarium\", \"plastic bag\", \"plate rack\", \"farm plow\", \"plunger\", \"Polaroid camera\", \"pole\", \"police van\", \"poncho\", \"pool table\", \"soda bottle\", \"plant pot\", \"potter's wheel\", \"power drill\", \"prayer rug\", \"printer\", \"prison\", \"missile\", \"projector\", \"hockey puck\", \"punching bag\", \"purse\", \"quill\", \"quilt\", \"race car\", \"racket\", \"radiator\", \"radio\", \"radio telescope\", \"rain barrel\", \"recreational vehicle\", \"fishing casting reel\", \"reflex camera\", \"refrigerator\", \"remote control\", \"restaurant\", \"revolver\", \"rifle\", \"rocking chair\", \"rotisserie\", \"eraser\", \"rugby ball\", \"ruler measuring stick\", \"sneaker\", \"safe\", \"safety pin\", \"salt shaker\", \"sandal\", \"sarong\", \"saxophone\", \"scabbard\", \"weighing scale\", \"school bus\", \"schooner\", \"scoreboard\", \"CRT monitor\", \"screw\", \"screwdriver\", \"seat belt\", \"sewing machine\", \"shield\", \"shoe store\", \"shoji screen / room divider\", \"shopping basket\", \"shopping cart\", \"shovel\", \"shower cap\", \"shower curtain\", \"ski\", \"balaclava ski mask\", \"sleeping bag\", \"slide rule\", \"sliding door\", \"slot machine\", \"snorkel\", \"snowmobile\", \"snowplow\", \"soap dispenser\", \"soccer ball\", \"sock\", \"solar thermal collector\", \"sombrero\", \"soup bowl\", \"keyboard space bar\", \"space heater\", \"space shuttle\", \"spatula\", \"motorboat\", \"spider web\", \"spindle\", \"sports car\", \"spotlight\", \"stage\", \"steam locomotive\", \"through arch bridge\", \"steel drum\", \"stethoscope\", \"scarf\", \"stone wall\", \"stopwatch\", \"stove\", \"strainer\", \"tram\", \"stretcher\", \"couch\", \"stupa\", \"submarine\", \"suit\", \"sundial\", \"sunglasses\", \"sunglasses\", \"sunscreen\", \"suspension bridge\", \"mop\", \"sweatshirt\", \"swim trunks / shorts\", \"swing\", \"electrical switch\", \"syringe\", \"table lamp\", \"tank\", \"tape player\", \"teapot\", \"teddy bear\", \"television\", \"tennis ball\", \"thatched roof\", \"front curtain\", \"thimble\", \"threshing machine\", \"throne\", \"tile roof\", \"toaster\", \"tobacco shop\", \"toilet seat\", \"torch\", \"totem pole\", \"tow truck\", \"toy store\", \"tractor\", \"semi-trailer truck\", \"tray\", \"trench coat\", \"tricycle\", \"trimaran\", \"tripod\", \"triumphal arch\", \"trolleybus\", \"trombone\", \"hot tub\", \"turnstile\", \"typewriter keyboard\", \"umbrella\", \"unicycle\", \"upright piano\", \"vacuum cleaner\", \"vase\", \"vaulted or arched ceiling\", \"velvet fabric\", \"vending machine\", \"vestment\", \"viaduct\", \"violin\", \"volleyball\", \"waffle iron\", \"wall clock\", \"wallet\", \"wardrobe\", \"military aircraft\", \"sink\", \"washing machine\", \"water bottle\", \"water jug\", \"water tower\", \"whiskey jug\", \"whistle\", \"hair wig\", \"window screen\", \"window shade\", \"Windsor tie\", \"wine bottle\", \"airplane wing\", \"wok\", \"wooden spoon\", \"wool\", \"split-rail fence\", \"shipwreck\", \"sailboat\", \"yurt\", \"website\", \"comic book\", \"crossword\", \"traffic or street sign\", \"traffic light\", \"dust jacket\", \"menu\", \"plate\", \"guacamole\", \"consomme\", \"hot pot\", \"trifle\", \"ice cream\", \"popsicle\", \"baguette\", \"bagel\", \"pretzel\", \"cheeseburger\", \"hot dog\", \"mashed potatoes\", \"cabbage\", \"broccoli\", \"cauliflower\", \"zucchini\", \"spaghetti squash\", \"acorn squash\", \"butternut squash\", \"cucumber\", \"artichoke\", \"bell pepper\", \"cardoon\", \"mushroom\", \"Granny Smith apple\", \"strawberry\", \"orange\", \"lemon\", \"fig\", \"pineapple\", \"banana\", \"jackfruit\", \"cherimoya (custard apple)\", \"pomegranate\", \"hay\", \"carbonara\", \"chocolate syrup\", \"dough\", \"meatloaf\", \"pizza\", \"pot pie\", \"burrito\", \"red wine\", \"espresso\", \"tea cup\", \"eggnog\", \"mountain\", \"bubble\", \"cliff\", \"coral reef\", \"geyser\", \"lakeshore\", \"promontory\", \"sandbar\", \"beach\", \"valley\", \"volcano\", \"baseball player\", \"bridegroom\", \"scuba diver\", \"rapeseed\", \"daisy\", \"yellow lady's slipper\", \"corn\", \"acorn\", \"rose hip\", \"horse chestnut seed\", \"coral fungus\", \"agaric\", \"gyromitra\", \"stinkhorn mushroom\", \"earth star fungus\", \"hen of the woods mushroom\", \"bolete\", \"corn cob\", \"toilet paper\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ImageNet-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetA(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for loading images from the ImageNet-A dataset.\n",
    "\n",
    "    Args:\n",
    "        root (str): The root directory of the dataset.\n",
    "        csvMapFile (str, optional): The path to the CSV file containing the mapping of WordNet IDs to class names. Defaults to \"dataloaders/wordNetIDs2Classes.csv\".\n",
    "        transform (callable, optional): A function/transform that takes in an image and returns a transformed version. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root, csvMapFile=\"wordNetIDs2Classes.csv\", transform=None\n",
    "    ):\n",
    "        self.s3_bucket = \"deeplearning2024-datasets\"\n",
    "        self.s3_region = \"eu-west-1\"\n",
    "        self.s3_client = boto3.client(\"s3\", region_name=self.s3_region, verify=True)\n",
    "\n",
    "        response = self.s3_client.list_objects_v2(Bucket=self.s3_bucket, Prefix=root)\n",
    "        objects = response.get(\"Contents\", [])\n",
    "        #print(objects)\n",
    "        while response.get(\"NextContinuationToken\"):\n",
    "            response = self.s3_client.list_objects_v2(\n",
    "                Bucket=self.s3_bucket,\n",
    "                Prefix=root,\n",
    "                ContinuationToken=response[\"NextContinuationToken\"]\n",
    "            )\n",
    "            objects.extend(response.get(\"Contents\", []))\n",
    "\n",
    "        mapping = {}\n",
    "        csv_file = csv.reader(open(csvMapFile, \"r\"))\n",
    "        for id, wordnet, name in csv_file:\n",
    "            if id == \"resnet_label\":\n",
    "                continue\n",
    "            mapping[int(wordnet)] = {\"id\": id, \"name\": name}\n",
    "\n",
    "        # print(mapping)\n",
    "        self.classnames = {}\n",
    "\n",
    "        # Iterate and keep valid files only\n",
    "        self.instances = []\n",
    "        for ds_idx, item in enumerate(objects):\n",
    "            key = item[\"Key\"]\n",
    "            path = Path(key)\n",
    "\n",
    "            # Check if file is valid\n",
    "            if path.suffix.lower() not in (\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\"):\n",
    "                continue\n",
    "\n",
    "            # Get label\n",
    "            label = int(path.parent.name[1:])\n",
    "            name = mapping[label][\"name\"]\n",
    "            self.classnames[mapping[label][\"id\"]] = name\n",
    "            label = int(mapping[label][\"id\"])\n",
    "\n",
    "\n",
    "            # Keep track of valid instances\n",
    "            self.instances.append((label, name, key))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            label, name, key = self.instances[idx]\n",
    "            # Download image from S3\n",
    "            # response = self.s3_client.get_object(Bucket=self.s3_bucket, Key=key)\n",
    "            # img_bytes = response[\"Body\"]._raw_stream.data\n",
    "\n",
    "            img_bytes = BytesIO()\n",
    "            self.s3_client.download_fileobj(Bucket=self.s3_bucket, Key=key, Fileobj=img_bytes)\n",
    "            img_bytes.seek(0)  # Ensure the BytesIO object is at the start\n",
    "            # Open image with PIL\n",
    "            img = Image.open(img_bytes).convert(\"RGB\")\n",
    "\n",
    "            # Apply transformations if any\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading image at index {idx}: {str(e)}\")\n",
    "\n",
    "        return {\"img\": img, \"label\": label, \"name\": name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ImageNet-V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetV2(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for loading images from the ImageNet-V2 dataset.\n",
    "\n",
    "    Args:\n",
    "        root (str): The root directory of the dataset.\n",
    "        csvMapFile (str, optional): The path to the CSV file containing the mapping of WordNet IDs to class names. Defaults to \"dataloaders/wordNetIDs2Classes.csv\".\n",
    "        transform (callable, optional): A function/transform that takes in an image and returns a transformed version. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root, csvMapFile=\"wordNetIDs2Classes.csv\", transform=None\n",
    "    ):\n",
    "        self.s3_bucket = \"deeplearning2024-datasets\"\n",
    "        self.s3_region = \"eu-west-1\"\n",
    "        self.s3_client = boto3.client(\"s3\", region_name=self.s3_region, verify=True)\n",
    "\n",
    "        response = self.s3_client.list_objects_v2(Bucket=self.s3_bucket, Prefix=root)\n",
    "        objects = response.get(\"Contents\", [])\n",
    "        while response.get(\"NextContinuationToken\"):\n",
    "            response = self.s3_client.list_objects_v2(\n",
    "                Bucket=self.s3_bucket,\n",
    "                Prefix=root,\n",
    "                ContinuationToken=response[\"NextContinuationToken\"]\n",
    "            )\n",
    "            objects.extend(response.get(\"Contents\", []))\n",
    "\n",
    "        mapping = {}\n",
    "        csv_file = csv.reader(open(csvMapFile, \"r\"))\n",
    "        for id, _, name in csv_file:\n",
    "            if id == \"resnet_label\":\n",
    "                continue\n",
    "            mapping[id] = name\n",
    "\n",
    "        self.classnames = {}\n",
    "        # Iterate and keep valid files only\n",
    "        self.instances = []\n",
    "        for ds_idx, item in enumerate(objects):\n",
    "            key = item[\"Key\"]\n",
    "            path = Path(key)\n",
    "\n",
    "            # Check if file is valid\n",
    "            if path.suffix.lower() not in (\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\"):\n",
    "                continue\n",
    "\n",
    "            # Get label\n",
    "            label = path.parent.name\n",
    "            name = mapping[label]\n",
    "            self.classnames[label] = name\n",
    "\n",
    "            label = int(label)\n",
    "\n",
    "            # Keep track of valid instances\n",
    "            self.instances.append((label, name, key))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            label, name, key = self.instances[idx]\n",
    "            # Download image from S3\n",
    "            # response = self.s3_client.get_object(Bucket=self.s3_bucket, Key=key)\n",
    "            # img_bytes = response[\"Body\"]._raw_stream.data\n",
    "\n",
    "            img_bytes = BytesIO()\n",
    "            self.s3_client.download_fileobj(Bucket=self.s3_bucket, Key=key, Fileobj=img_bytes)\n",
    "            img_bytes.seek(0)  # Ensure the BytesIO object is at the start\n",
    "            # Open image with PIL\n",
    "            img = Image.open(img_bytes).convert(\"RGB\")\n",
    "\n",
    "            # Apply transformations if any\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading image at index {idx}: {str(e)}\")\n",
    "\n",
    "        return {\"img\": img, \"label\": label, \"name\": name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EasyAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyAgumenter(object):\n",
    "    def __init__(self, base_transform, preprocess, augmentation, n_views=63):\n",
    "        self.base_transform = base_transform\n",
    "        self.preprocess = preprocess\n",
    "        self.n_views = n_views\n",
    "\n",
    "        if augmentation == 'augmix':\n",
    "\n",
    "            self.preaugment = transforms.Compose(\n",
    "                [\n",
    "                    AugMix(),\n",
    "                    transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "                    transforms.CenterCrop(224),\n",
    "                ]\n",
    "            )\n",
    "        elif augmentation == 'identity':\n",
    "            self.preaugment = self.base_transform\n",
    "        elif augmentation == 'cut':\n",
    "            self.preaugment = transforms.Compose(\n",
    "                [\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError('Augmentation type not recognized')\n",
    "    \n",
    "    def __call__(self, x):\n",
    "\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = transforms.ToPILImage()(x)\n",
    "\n",
    "        image = self.preprocess(self.base_transform(x))\n",
    "\n",
    "        views = [self.preprocess(self.preaugment(x)) for _ in range(self.n_views)]\n",
    "\n",
    "        return [image] + views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(root, transform=None, csvMapFile=\"wordNetIDs2Classes.csv\"):\n",
    "    \"\"\"\n",
    "    Returns the dataloader of the dataset.\n",
    "\n",
    "    Args:\n",
    "        root (str): The root directory of the dataset.\n",
    "        transform (callable, optional): A function/transform that takes in an image and returns a transformed version. Defaults to None.\n",
    "    \"\"\"\n",
    "    root_A = \"imagenet-a\"\n",
    "    imageNet_A = ImageNetA(root_A, transform=transform, csvMapFile=csvMapFile)\n",
    "    root_V2 = \"imagenetv2-matched-frequency-format-val\"\n",
    "    imageNet_V2 = ImageNetV2(root_V2, transform=transform, csvMapFile=csvMapFile)\n",
    "\n",
    "    return imageNet_A, imageNet_V2\n",
    "\n",
    "def get_classes_names(csvMapFile=\"wordNetIDs2Classes.csv\"):\n",
    "    \"\"\"\n",
    "    Returns the class names of the dataset.\n",
    "\n",
    "    Args:\n",
    "        csvMapFile (str, optional): The path to the CSV file containing the mapping of WordNet IDs to class names. Defaults to \"dataloaders/wordNetIDs2Classes.csv\".\n",
    "    \"\"\"\n",
    "    names = [\"\"]*1000\n",
    "    csv_file = csv.reader(open(csvMapFile, 'r'))\n",
    "    for id, wordnet, name in csv_file:\n",
    "        if id == 'resnet_label':\n",
    "            continue\n",
    "        names[int(id)] = name\n",
    "    \n",
    "    return names\n",
    "\n",
    "def memo_get_datasets(augmentation, augs=64):\n",
    "    \"\"\"\n",
    "    Returns the ImageNetA and ImageNetV2 datasets for the memo model\n",
    "    Args:\n",
    "        augmentation (str): What type of augmentation to use in EasyAugmenter. Can be 'augmix', 'identity' or 'cut'\n",
    "        augs (int): The number of augmentations to compute. Must be greater than 1\n",
    "\n",
    "    Returns: The ImageNetA and ImageNetV2 datasets for the memo model, with the Augmentations already applied\n",
    "\n",
    "    \"\"\"\n",
    "    assert augs > 1, 'The number of augmentations must be greater than 1'\n",
    "    memo_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                          transforms.CenterCrop(224)])\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    transform = EasyAgumenter(memo_transforms, preprocess, augmentation, augs - 1)\n",
    "    imageNet_A, imageNet_V2 = get_dataloaders('OfficeHomeDataset_10072016', transform)\n",
    "    return imageNet_A, imageNet_V2\n",
    "\n",
    "def tpt_get_transforms(augs=64):\n",
    "\n",
    "    base_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.CenterCrop(224),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                std=[0.26862954, 0.26130258, 0.27577711],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data_transform = EasyAgumenter(\n",
    "        base_transform,\n",
    "        preprocess,\n",
    "        n_views=augs - 1,\n",
    "    )\n",
    "\n",
    "    return data_transform\n",
    "\n",
    "\n",
    "def tpt_get_datasets(data_root, augmix=False, augs=64, all_classes=True):\n",
    "    \"\"\"\n",
    "    Returns the ImageNetA and ImageNetV2 datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - data_root (str): The root directory of the datasets.\n",
    "    - augmix (bool): Whether to use AugMix or not.\n",
    "    - augs (int): The number of augmentations to use.\n",
    "    - all_classes (bool): Whether to use all classes or not.\n",
    "\n",
    "    Returns:\n",
    "    - imageNet_A (ImageNetA): The ImageNetA dataset.\n",
    "    - ima_names (list): The original classnames in ImageNetA.\n",
    "    - ima_custom_names (list): The retouched  classnames in ImageNetA.\n",
    "    - ima_id_mapping (list): The mapping between the index of the classname and the ImageNet label\n",
    "\n",
    "    same for ImageNetV2\n",
    "\n",
    "    For instance the first element of ima_names corresponds to the label '90'.  After running the\n",
    "    inference run the predicted output through the ima_id_mapping to recover the correct class label.\n",
    "\n",
    "    out = tpt(inputs)\n",
    "    pred = out.argmax().item()\n",
    "    out_id = ima_id_mapping[pred]\n",
    "\n",
    "    \"\"\"\n",
    "    base_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.CenterCrop(224),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                std=[0.26862954, 0.26130258, 0.27577711],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data_transform = EasyAgumenter(\n",
    "        base_transform,\n",
    "        preprocess,\n",
    "        augmentation=(\"augmix\" if augmix else \"cut\"),\n",
    "        n_views=augs - 1,\n",
    "    )\n",
    "\n",
    "    imageNet_A = ImageNetA(\n",
    "        \"imagenet-a\", transform=data_transform\n",
    "    )\n",
    "    imageNet_V2 = ImageNetV2(\n",
    "        \"imagenetv2-matched-frequency-format-val\",\n",
    "        transform=data_transform,\n",
    "    )\n",
    "\n",
    "    imv2_label_mapping = list(imageNet_V2.classnames.keys())\n",
    "    imv2_names = list(imageNet_V2.classnames.values())\n",
    "    imv2_custom_names = [imagenet_classes[int(i)] for i in imv2_label_mapping]\n",
    "\n",
    "    ima_label_mapping = list(imageNet_A.classnames.keys())\n",
    "    ima_names = list(imageNet_A.classnames.values())\n",
    "    ima_custom_names = [imagenet_classes[int(i)] for i in ima_label_mapping]\n",
    "\n",
    "    if all_classes:\n",
    "        ima_names += [name for name in imv2_names if name not in ima_names]\n",
    "        ima_custom_names += [\n",
    "            name for name in imv2_custom_names if name not in ima_custom_names\n",
    "        ]\n",
    "        ima_label_mapping += [\n",
    "            map for map in imv2_label_mapping if map not in ima_label_mapping\n",
    "        ]\n",
    "\n",
    "    return (\n",
    "        imageNet_A,\n",
    "        ima_names,\n",
    "        ima_custom_names,\n",
    "        ima_label_mapping,\n",
    "        imageNet_V2,\n",
    "        imv2_names,\n",
    "        imv2_custom_names,\n",
    "        imv2_label_mapping,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyPromptLearner(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        clip,\n",
    "        base_prompt=\"a photo of [CLS]\",\n",
    "        splt_ctx=False,\n",
    "        classnames=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.base_prompt = base_prompt\n",
    "        self.tkn_embedder = clip.token_embedding\n",
    "        # set requires_grad to False\n",
    "        self.tkn_embedder.requires_grad_(False)\n",
    "\n",
    "        self.split_ctx = splt_ctx\n",
    "\n",
    "        self.prepare_prompts(classnames)\n",
    "\n",
    "    def prepare_prompts(self, classnames):\n",
    "        print(\"[PromptLearner] Preparing prompts\")\n",
    "\n",
    "        self.classnames = classnames\n",
    "        # self.classnames = [cls.split(\",\")[0] for cls in self.classnames]\n",
    "\n",
    "        # get numbr of classes\n",
    "        self.cls_num = len(self.classnames)\n",
    "\n",
    "        # get prompt text prefix and suffix\n",
    "        txt_prefix = self.base_prompt.split(\"[CLS]\")[0]\n",
    "        txt_suffix = self.base_prompt.split(\"[CLS]\")[1]\n",
    "\n",
    "        # tokenize the prefix and suffix\n",
    "        tkn_prefix = tokenize(txt_prefix)\n",
    "        tkn_suffix = tokenize(txt_suffix)\n",
    "        tkn_pad = tokenize(\"\")\n",
    "        tkn_cls = tokenize(self.classnames)\n",
    "\n",
    "        # get the index of the last element of the prefix and suffix\n",
    "        idx = torch.arange(tkn_prefix.shape[1], 0, -1)\n",
    "        self.indp = torch.argmax((tkn_prefix == 0) * idx, 1, keepdim=True)\n",
    "        self.inds = torch.argmax((tkn_suffix == 0) * idx, 1, keepdim=True)\n",
    "\n",
    "        # token length for each class\n",
    "        self.indc = torch.argmax((tkn_cls == 0) * idx, 1, keepdim=True)\n",
    "\n",
    "        # get the prefix, suffix, SOT and EOT\n",
    "        self.tkn_sot = tkn_prefix[:, :1]\n",
    "        self.tkn_prefix = tkn_prefix[:, 1 : self.indp - 1]\n",
    "        self.tkn_suffix = tkn_suffix[:, 1 : self.inds - 1]\n",
    "        self.tkn_eot = tkn_suffix[:, self.inds - 1 : self.inds]\n",
    "        self.tkn_pad = tkn_pad[:, 2:]\n",
    "\n",
    "        # load segments to CUDA, be ready to be embedded\n",
    "        self.tkn_sot = self.tkn_sot.to(self.device)\n",
    "        self.tkn_prefix = self.tkn_prefix.to(self.device)\n",
    "        self.tkn_suffix = self.tkn_suffix.to(self.device)\n",
    "        self.tkn_eot = self.tkn_eot.to(self.device)\n",
    "        self.tkn_pad = self.tkn_pad.to(self.device)\n",
    "\n",
    "        self.tkn_cls = tkn_cls.to(self.device)\n",
    "\n",
    "        # gets the embeddings\n",
    "        with torch.no_grad():\n",
    "            self.emb_sot = self.tkn_embedder(self.tkn_sot)\n",
    "            self.emb_prefix = self.tkn_embedder(self.tkn_prefix)\n",
    "            self.emb_suffix = self.tkn_embedder(self.tkn_suffix)\n",
    "            self.emb_eot = self.tkn_embedder(self.tkn_eot)\n",
    "            self.emb_cls = self.tkn_embedder(self.tkn_cls)\n",
    "            self.emb_pad = self.tkn_embedder(self.tkn_pad)\n",
    "\n",
    "        # take out the embeddings of the class tokens (they are different lenghts)\n",
    "        self.all_cls = []\n",
    "        for i in range(self.cls_num):\n",
    "            self.all_cls.append(self.emb_cls[i][1 : self.indc[i] - 1])\n",
    "\n",
    "        # prepare the prompts, they are needed for text encoding\n",
    "        self.txt_prompts = [\n",
    "            self.base_prompt.replace(\"[CLS]\", cls) for cls in self.classnames\n",
    "        ]\n",
    "        self.tkn_prompts = tokenize(self.txt_prompts)\n",
    "\n",
    "        # set the inital context, this will be reused at every new inference\n",
    "        # this is the context that will be optimized\n",
    "\n",
    "        if self.split_ctx:\n",
    "            self.pre_init_state = self.emb_prefix.detach().clone()\n",
    "            self.suf_init_state = self.emb_suffix.detach().clone()\n",
    "            self.emb_prefix = nn.Parameter(self.emb_prefix)\n",
    "            self.emb_suffix = nn.Parameter(self.emb_suffix)\n",
    "            self.register_parameter(\"emb_prefix\", self.emb_prefix)\n",
    "            self.register_parameter(\"emb_suffix\", self.emb_suffix)\n",
    "        else:\n",
    "            self.ctx = torch.cat((self.emb_prefix, self.emb_suffix), dim=1)\n",
    "            self.ctx_init_state = self.ctx.detach().clone()\n",
    "            self.ctx = nn.Parameter(self.ctx)\n",
    "            self.register_parameter(\"ctx\", self.ctx)\n",
    "\n",
    "    def build_ctx(self):\n",
    "        prompts = []\n",
    "        for i in range(self.cls_num):\n",
    "            pad_size = self.emb_cls.shape[1] - (\n",
    "                self.emb_prefix.shape[1]\n",
    "                + self.indc[i].item()\n",
    "                + self.emb_suffix.shape[1]\n",
    "            )\n",
    "\n",
    "            if self.split_ctx:\n",
    "                prefix = self.emb_prefix\n",
    "                suffix = self.emb_suffix\n",
    "            else:\n",
    "                prefix = self.ctx[:, : self.emb_prefix.shape[1]]\n",
    "                suffix = self.ctx[:, self.emb_prefix.shape[1] :]\n",
    "\n",
    "            prompt = torch.cat(\n",
    "                (\n",
    "                    self.emb_sot,\n",
    "                    prefix,\n",
    "                    self.all_cls[i].unsqueeze(0),\n",
    "                    suffix,\n",
    "                    self.emb_eot,\n",
    "                    self.emb_pad[:, :pad_size],\n",
    "                ),\n",
    "                dim=1,\n",
    "            )\n",
    "            prompts.append(prompt)\n",
    "        prompts = torch.cat(prompts, dim=0)\n",
    "\n",
    "        return prompts\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        return self.build_ctx()\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        if self.split_ctx:\n",
    "            self.emb_prefix.data.copy_(self.pre_init_state)  # to be optimized\n",
    "            self.emb_suffix.data.copy_(self.suf_init_state)  # to be optimized\n",
    "        else:\n",
    "            self.ctx.data.copy_(self.ctx_init_state)  # to be optimized\n",
    "\n",
    "\n",
    "class EasyTPT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        base_prompt=\"a photo of a [CLS]\",\n",
    "        arch=\"RN50\",\n",
    "        splt_ctx=False,\n",
    "        classnames=None,\n",
    "        ttt_steps=1,\n",
    "        augs=64,\n",
    "        lr=0.005,\n",
    "    ):\n",
    "        super(EasyTPT, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        ###TODO: tobe parametrized\n",
    "        DOWNLOAD_ROOT = \"~/.cache/clip\"\n",
    "        ###\n",
    "\n",
    "        self.base_prompt = base_prompt\n",
    "        self.ttt_steps = ttt_steps\n",
    "        self.augs = augs\n",
    "        self.selected_idx = None\n",
    "\n",
    "        # Load clip\n",
    "        clip, self.preprocess = load(arch, device=device, download_root=DOWNLOAD_ROOT)\n",
    "        self.clip = clip\n",
    "        self.dtype = clip.dtype\n",
    "        self.image_encoder = clip.encode_image\n",
    "        self.text_encoder = clip.encode_text\n",
    "\n",
    "        # freeze the parameters\n",
    "        for name, param in self.named_parameters():\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "        # create the prompt learner\n",
    "        self.prompt_learner = EasyPromptLearner(\n",
    "            device, clip, base_prompt, splt_ctx, classnames\n",
    "        )\n",
    "\n",
    "        # create optimizer and save the state\n",
    "        trainable_param = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f\"[EasyTPT] Training parameter: {name}\")\n",
    "                trainable_param.append(param)\n",
    "        self.optimizer = torch.optim.AdamW(trainable_param, lr)\n",
    "        self.optim_state = deepcopy(self.optimizer.state_dict())\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "    def forward(self, x, top=0.10):\n",
    "        \"\"\"\n",
    "        If x is a list of augmentations, run the confidence selection,\n",
    "        otherwise just run the inference\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        # breakpoint()\n",
    "        if isinstance(x, list):\n",
    "            x = torch.stack(x).to(self.device)\n",
    "            logits = self.inference(x)\n",
    "            if self.selected_idx is not None:\n",
    "                logits = logits[self.selected_idx]\n",
    "            else:\n",
    "                logits, self.selected_idx = self.select_confident_samples(logits, top)\n",
    "        else:\n",
    "            if len(x.shape) == 3:\n",
    "                x = x.unsqueeze(0)\n",
    "            x = x.to(self.device)\n",
    "            logits = self.inference(x)\n",
    "        \n",
    "        # print (f\"[EasyTPT] input shape: {x.shape}\")\n",
    "        # print(\"[EasyTPT] logits shape: \", logits.shape)\n",
    "        return logits\n",
    "\n",
    "    def inference(self, x):\n",
    "        with torch.no_grad():\n",
    "            image_feat = self.image_encoder(x)\n",
    "            image_feat = image_feat / image_feat.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        emb_prompts = self.prompt_learner()\n",
    "\n",
    "        txt_features = self.custom_encoder(emb_prompts, self.prompt_learner.tkn_prompts)\n",
    "        txt_features = txt_features / txt_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        logit_scale = self.clip.logit_scale.exp()\n",
    "        logits = logit_scale * image_feat @ txt_features.t()\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def custom_encoder(self, prompts, tokenized_prompts):\n",
    "        \"\"\"\n",
    "        Custom clip text encoder, unlike the original clip encoder this one\n",
    "        takes the prompts embeddings from the prompt learner\n",
    "        \"\"\"\n",
    "        x = prompts + self.clip.positional_embedding\n",
    "        x = x.permute(1, 0, 2).type(self.dtype)  # NLD -> LND\n",
    "        x = self.clip.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.clip.ln_final(x).type(self.dtype)\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = (\n",
    "            x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)]\n",
    "            @ self.clip.text_projection\n",
    "        )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the optimizer and the prompt learner to their initial state,\n",
    "        this has to be run before each new test\n",
    "        \"\"\"\n",
    "        self.optimizer.load_state_dict(deepcopy(self.optim_state))\n",
    "        self.prompt_learner.reset()\n",
    "        self.selected_idx = None\n",
    "\n",
    "    def select_confident_samples(self, logits, top):\n",
    "        \"\"\"\n",
    "        Performs confidence selection, will return the indexes of the\n",
    "        augmentations with the highest confidence as well as the filtered\n",
    "        logits\n",
    "\n",
    "        Parameters:\n",
    "        - logits (torch.Tensor): the logits of the model [NAUGS, NCLASSES]\n",
    "        - top (float): the percentage of top augmentations to use\n",
    "        \"\"\"\n",
    "        batch_entropy = -(logits.softmax(1) * logits.log_softmax(1)).sum(1)\n",
    "        idx = torch.argsort(batch_entropy, descending=False)[\n",
    "            : int(batch_entropy.size()[0] * top)\n",
    "        ]\n",
    "        return logits[idx], idx\n",
    "\n",
    "    def tpt_avg_entropy(self, outputs):\n",
    "        logits = outputs - outputs.logsumexp(\n",
    "            dim=-1, keepdim=True\n",
    "        )  # logits = outputs.log_softmax(dim=1) [N, 1000]\n",
    "        avg_logits = logits.logsumexp(dim=0) - np.log(\n",
    "            logits.shape[0]\n",
    "        )  # avg_logits = logits.mean(0) [1, 1000]\n",
    "        min_real = torch.finfo(avg_logits.dtype).min\n",
    "        avg_logits = torch.clamp(avg_logits, min=min_real)\n",
    "        return -(avg_logits * torch.exp(avg_logits)).sum(dim=-1)\n",
    "\n",
    "    def predict(self, images, niter=1):\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        for _ in range(niter):\n",
    "            out = self(images)\n",
    "            loss = self.tpt_avg_entropy(out)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            out = self(images[0])\n",
    "            out_id = out.argmax(1).item()\n",
    "            prediction = self.prompt_learner.classnames[out_id]\n",
    "\n",
    "        # return out_id, prediction\n",
    "        return out_id\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        \"\"\"\n",
    "        Returns the optimizer\n",
    "\n",
    "        Returns:\n",
    "        - torch.optim: the optimizer\n",
    "        \"\"\"\n",
    "        return self.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo_marginal_entropy(outputs):\n",
    "    logits = outputs - outputs.logsumexp(dim=-1, keepdim=True)\n",
    "    avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0])\n",
    "    min_real = torch.finfo(avg_logits.dtype).min\n",
    "    avg_logits = torch.clamp(avg_logits, min=min_real)\n",
    "    return -(avg_logits * torch.exp(avg_logits)).sum(dim=-1)\n",
    "\n",
    "\n",
    "def _modified_bn_forward(self, input):\n",
    "    est_mean = torch.zeros(self.running_mean.shape, device=self.running_mean.device)\n",
    "    est_var = torch.ones(self.running_var.shape, device=self.running_var.device)\n",
    "    nn.functional.batch_norm(input, est_mean, est_var, None, None, True, 1.0, self.eps)\n",
    "    running_mean = self.prior * self.running_mean + (1 - self.prior) * est_mean\n",
    "    running_var = self.prior * self.running_var + (1 - self.prior) * est_var\n",
    "    return nn.functional.batch_norm(input, running_mean, running_var, self.weight, self.bias, False, 0, self.eps)\n",
    "\n",
    "\n",
    "class EasyMemo(nn.Module):\n",
    "    \"\"\"\n",
    "    A class to wrap a neural network with the MEMO TTA method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net, device, classes_mask, prior_strength: float = 1.0, lr=0.005, weight_decay=0.0001, opt='sgd',\n",
    "                 niter=1, top=0.1, drop=False):\n",
    "        \"\"\"\n",
    "        Initializes the EasyMemo model with various arguments\n",
    "        Args:\n",
    "            net: The model to wrap with EasyMemo\n",
    "            device: The device to run the model on(usually 'CPU' or 'CUDA')\n",
    "            classes_mask: The classes to consider for the model(used for Imagenet-A)\n",
    "            prior_strength: The strength of the prior to use in the modified BN forward pass\n",
    "            lr: The Learning rate for the optimizer of the model\n",
    "            weight_decay: The weight decay for the optimizer of the model\n",
    "            opt: Which optimizer to use for this model between 'sgd' and 'adamw' for the respective optimizers\n",
    "            niter: The number of iterations to run the memo pass for\n",
    "            top: The percentage of the top logits to consider for confidence selection\n",
    "        \"\"\"\n",
    "        super(EasyMemo, self).__init__()\n",
    "\n",
    "        self.drop = drop\n",
    "        if self.drop:\n",
    "            net.layer4.add_module('dropout', nn.Dropout(0.5, inplace=True))\n",
    "        self.device = device\n",
    "        self.prior_strength = prior_strength\n",
    "        self.net = net.to(device)\n",
    "        self.optimizer = self.memo_optimizer_model(lr=lr, weight_decay=weight_decay, opt=opt)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.opt = opt\n",
    "        self.confidence_idx = None\n",
    "        self.memo_modify_bn_pass()\n",
    "        self.criterion = memo_marginal_entropy\n",
    "        self.niter = niter\n",
    "        self.top = top\n",
    "        self.initial_state = deepcopy(self.net.state_dict())\n",
    "        self.classes_mask = classes_mask\n",
    "\n",
    "    def forward(self, x, top=-1):\n",
    "        \"\"\"\n",
    "        Forward pass where we check which type of input we have and we call the inference on the input image Tensor\n",
    "        Args:\n",
    "            top: How many samples to select from the batch\n",
    "            x: A Tensor of shape (N, C, H, W) or a list of Tensors of shape (N, C, H, W)\n",
    "\n",
    "        Returns: The logits after the inference pass\n",
    "\n",
    "        \"\"\"\n",
    "        self.top = top if top > 0 else self.top\n",
    "        # print(f\"Shape forward: {x.shape}\")\n",
    "        if isinstance(x, list):\n",
    "            x = torch.stack(x).to(self.device)\n",
    "            # print(f\"Shape forward: {x.shape}\")\n",
    "            logits = self.inference(x)\n",
    "            logits, self.confidence_idx = self.topk_selection(logits)\n",
    "        else:\n",
    "            if len(x.shape) == 3:\n",
    "                x = x.unsqueeze(0)\n",
    "            x = x.to(self.device)\n",
    "            logits = self.inference(x)\n",
    "\n",
    "        # print(f\"[EasyMemo] input shape: {x.shape}\")\n",
    "        # print(f\"[EasyMemo] logits shape: {logits.shape}\")\n",
    "        return logits\n",
    "\n",
    "    def inference(self, x):\n",
    "        \"\"\"\n",
    "        Return the logits of the image in input x\n",
    "        Args:\n",
    "            x: A Tensor of shape (N, C, H, W) of an Image\n",
    "\n",
    "        Returns: The logits for that Tensor image\n",
    "\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        outputs = self.net(x)\n",
    "\n",
    "        out_app = torch.zeros(outputs.shape[0], len(self.classes_mask)).to(self.device)\n",
    "        for i, out in enumerate(outputs):\n",
    "            out_app[i] = out[self.classes_mask]\n",
    "        return out_app\n",
    "\n",
    "    def predict(self, x, niter=1):\n",
    "        \"\"\"\n",
    "        Predicts the class of the input x, which is an image\n",
    "        Args:\n",
    "            niter: The number of iteration on which to run the memo pass\n",
    "            x: Tensor of shape (N, C, H, W)\n",
    "\n",
    "        Returns: The predicted classes\n",
    "\n",
    "        \"\"\"\n",
    "        self.niter = niter\n",
    "        if self.drop:\n",
    "            self.net.train()\n",
    "        else:\n",
    "            self.net.eval()\n",
    "\n",
    "        for iteration in range(self.niter):\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.forward(x)\n",
    "            outputs, _ = self.topk_selection(outputs)\n",
    "            loss = self.criterion(outputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.net(x[0].unsqueeze(0).to(self.device))\n",
    "            outs = torch.zeros(outputs.shape[0], len(self.classes_mask)).to(self.device)\n",
    "            for i, out in enumerate(outputs):\n",
    "                outs[i] = out[self.classes_mask]\n",
    "            predicted = outs.argmax(1).item()\n",
    "\n",
    "        return predicted\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the model to its initial state\"\"\"\n",
    "        del self.optimizer\n",
    "        self.optimizer = self.memo_optimizer_model(lr=self.lr, weight_decay=self.weight_decay, opt=self.opt)\n",
    "        self.confidence_idx = None\n",
    "        self.net.load_state_dict(deepcopy(self.initial_state))\n",
    "\n",
    "    def memo_modify_bn_pass(self):\n",
    "        print('modifying BN forward pass')\n",
    "        nn.BatchNorm2d.prior = self.prior_strength\n",
    "        nn.BatchNorm2d.forward = _modified_bn_forward\n",
    "\n",
    "    def memo_optimizer_model(self, lr=0.005, weight_decay=0.0001, opt='sgd'):\n",
    "        \"\"\"\n",
    "        Initializes the optimizer for the memo model\n",
    "        Args:\n",
    "            lr: The learning rate for the optimizer\n",
    "            weight_decay: The weight decay for the optimizer\n",
    "            opt: Which optimizer to use\n",
    "\n",
    "        Returns: The optimizer for the memo model\n",
    "\n",
    "        \"\"\"\n",
    "        if opt == 'sgd':\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif opt == 'adamw':\n",
    "            optimizer = optim.AdamW(self.net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise ValueError('Invalid optimizer selected')\n",
    "        return optimizer\n",
    "\n",
    "    def memo_adapt_single(self, inputs):\n",
    "        \"\"\"\n",
    "        A single step of memo adaptation\n",
    "        Args:\n",
    "            inputs: A tensor of shape (N, C, H, W)\n",
    "\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        assert self.niter > 0 and isinstance(self.niter, int), 'niter must be a positive integer'\n",
    "        for iteration in range(self.niter):\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.net(inputs)\n",
    "            loss = self.criterion(outputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def memo_test_single(self, image, label):\n",
    "        \"\"\"\n",
    "        Tests the model on a single image and returns the correctness and confidence\n",
    "        Args:\n",
    "            image: A tensor of shape (N, C, H, W)\n",
    "            label: The correct label for the test\n",
    "\n",
    "        Returns: The correctness and confidence of the prediction\n",
    "\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.net(image.to(device=self.device))\n",
    "            _, predicted = outputs.max(1)\n",
    "            confidence = nn.functional.softmax(outputs, dim=1).squeeze()[predicted].item()\n",
    "        correctness = 1 if predicted.item() == label else 0\n",
    "        return correctness, confidence\n",
    "\n",
    "    def topk_selection(self, logits):\n",
    "        \"\"\"\n",
    "        Selects the top k logits based on the batch entropy\n",
    "        Args:\n",
    "            logits: A tensor of shape (N, C)\n",
    "\n",
    "        Returns: The filtered logits and the indices of the selected logits\n",
    "\n",
    "        \"\"\"\n",
    "        batch_entropy = -(logits.softmax(1) * logits.log_softmax(1)).sum(1)\n",
    "        selected_idx = torch.argsort(batch_entropy, descending=False)[: int(batch_entropy.size()[0] * self.top)]\n",
    "        return logits[selected_idx], selected_idx\n",
    "\n",
    "    def dropout_train(self, x):\n",
    "        self.net.train()\n",
    "        outputs = self.forward(x)\n",
    "        outputs, _ = self.topk_selection(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble class. Implements an ensemble of models with entropy minimization.\n",
    "\n",
    "    Attributes:\n",
    "        models (list): A list of models to be used in the ensemble.\n",
    "        temps (list): A list of temperature values corresponding to each model.\n",
    "        test_single_models (bool): Whether to test each individual model in addition to the ensemble.\n",
    "        backward (bool): Whether to perform the entropy minimization step.\n",
    "        device (str): The device to be used for computation.\n",
    "    \"\"\"\n",
    "    def __init__(self, models, temps, device=\"cuda\", test_single_models=False, no_backwards=False):\n",
    "        \"\"\"\n",
    "        Initializes an Ensemble object.\n",
    "\n",
    "        Args:\n",
    "            models (list): A list of models to be used in the ensemble.\n",
    "            temps (list): A list of temperature values corresponding to each model.\n",
    "            device (str, optional): The device to be used for computation. Defaults to \"cuda\".\n",
    "            test_single_models (bool, optional): Whether to test each individual model in addition to the ensemble. Defaults to False.\n",
    "            no_backwards (bool, optional): Whether to perform the entropy minimization step. Defaults to False.\n",
    "        \"\"\"\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.models = models\n",
    "        self.temps = temps\n",
    "        self.test_single_models = test_single_models\n",
    "        self.device = device\n",
    "        self.no_backwards = no_backwards\n",
    "\n",
    "    def entropy(self, logits):\n",
    "        \"\"\"\n",
    "        Computes the entropy of a set of logits.\n",
    "\n",
    "        Args:\n",
    "            logits (torch.Tensor): The logits to compute the entropy of.\n",
    "        \"\"\"\n",
    "        return -(torch.exp(logits) * logits).sum(dim=-1)\n",
    "\n",
    "    def marginal_distribution(self, models_logits):\n",
    "        \"\"\"\n",
    "        Computes the marginal distribution of the ensemble.\n",
    "\n",
    "        Args:\n",
    "            models_logits (torch.Tensor): The logits of the models in the ensemble.\n",
    "        \"\"\"\n",
    "        # average logits for each model\n",
    "        avg_models_logits = torch.Tensor(models_logits.shape[0], models_logits.shape[2]).to(self.device)\n",
    "        for i, model_logits in enumerate(models_logits):\n",
    "            avg_outs = torch.logsumexp(model_logits, dim=0) - torch.log(torch.tensor(model_logits.shape[0]))\n",
    "            min_real = torch.finfo(avg_outs.dtype).min\n",
    "            avg_outs = torch.clamp(avg_outs, min=min_real)\n",
    "            avg_outs /= self.temps[i]\n",
    "            avg_models_logits[i] = torch.log_softmax(avg_outs, dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            entropies = torch.stack([self.entropy(logits) for logits in avg_models_logits]).to(self.device)\n",
    "            sum_entropies = torch.sum(entropies, dim=0)\n",
    "            scale = torch.stack([sum_entropies/entopy for entopy in entropies]).to(self.device)\n",
    "            #normalize sum to 1\n",
    "            scale = scale / torch.sum(scale)\n",
    "\n",
    "        print(\"\\t\\t[Ensemble] Entropies: \", entropies)\n",
    "        print(\"\\t\\t[Ensemble] Scales: \", scale)\n",
    "\n",
    "        avg_logits = torch.sum(torch.stack([scale[i].item() * avg_models_logits[i] for i in range(len(avg_models_logits))]), dim=0)\n",
    "\n",
    "        return avg_logits\n",
    "\n",
    "    def get_models_outs(self, inputs, top=0.1):\n",
    "        \"\"\"\n",
    "        Computes the outputs of the models in the ensemble.\n",
    "\n",
    "        Args:\n",
    "            inputs (list): A list of inputs to be fed to the models.\n",
    "            top (float, optional): The top percentage of the outputs to be used. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        model_outs = torch.stack([model(inputs[i], top).to(self.device) for i, model in enumerate(self.models)]).to(self.device)\n",
    "        return model_outs.to(self.device)\n",
    "\n",
    "    def get_models_predictions(self, inputs):\n",
    "        \"\"\"\n",
    "        Computes the predictions of the single models in the ensemble.\n",
    "\n",
    "        Args:\n",
    "            inputs (list): A list of inputs to be fed to the models.\n",
    "        \"\"\"\n",
    "        models_pred = [model.predict(inputs[i]) for i, model in enumerate(self.models)]\n",
    "        return models_pred\n",
    "\n",
    "    def entropy_minimization(self, inputs, niter=1, top=0.1):\n",
    "        \"\"\"\n",
    "        Test time adaptation step. Minimizes the entropy of the ensemble's predictions.\n",
    "\n",
    "        Args:\n",
    "            inputs (list): A list of inputs to be fed to the models.\n",
    "            niter (int, optional): The number of iterations to perform. Defaults to 1.\n",
    "            top (float, optional): The top percentage of the outputs to be used. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        for i in range(niter):\n",
    "            outs = self.get_models_outs(inputs, top)\n",
    "            avg_logit = self.marginal_distribution(outs)\n",
    "\n",
    "            loss = self.entropy(avg_logit)\n",
    "            loss.backward()\n",
    "            for model in self.models:\n",
    "                model.optimizer.step()\n",
    "                model.optimizer.zero_grad()\n",
    "\n",
    "    def forward(self, inputs, niter=1, top=0.1):\n",
    "        \"\"\"\n",
    "        Forward pass of the ensemble.\n",
    "\n",
    "        Args:\n",
    "            inputs (list): A list of inputs to be fed to the models.\n",
    "            niter (int, optional): The number of iterations to perform. Defaults to 1.\n",
    "            top (float, optional): The top percentage of the outputs to be used. Defaults to 0.1.\n",
    "        \"\"\"\n",
    "        # get models outputs\n",
    "        self.reset()\n",
    "        models_pred = self.get_models_predictions(inputs)\n",
    "\n",
    "        self.reset()\n",
    "        self.entropy_minimization(inputs, niter, top)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            outs = self.get_models_outs([i[0] for i in inputs], top)\n",
    "            avg_logit = self.marginal_distribution(outs)\n",
    "            prediction = torch.argmax(avg_logit, dim=0)\n",
    "\n",
    "        if self.no_backwards:\n",
    "            self.reset()\n",
    "            outs = self.get_models_outs(inputs, top)\n",
    "            avg_logit = self.marginal_distribution(outs)\n",
    "            prediction_no_back = torch.argmax(avg_logit, dim=0)\n",
    "\n",
    "        return models_pred, prediction_no_back, prediction\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the models in the ensemble.\n",
    "        \"\"\"\n",
    "        for model in self.models:\n",
    "            model.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Time Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prepare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPT(device=\"cuda\", naug=30, base_prompt=\"A bad photo of a [CLS].\", arch=\"RN50\", splt_ctx= True, A=True):\n",
    "    # prepare TPT\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Using CPU this is no bueno\")\n",
    "    else:\n",
    "        print(\"Using GPU, brace yourself!\")\n",
    "\n",
    "    datasetRoot = \"OfficeHomeDataset_10072016\"\n",
    "    imageNetA, _, imageNetACustomNames, imageNetAMap, imageNetV2, _, imageNetV2CustomNames, imageNetV2Map = tpt_get_datasets(datasetRoot, augs=naug, all_classes=False)\n",
    "    \n",
    "    if A:\n",
    "        dataset = imageNetA\n",
    "        classnames = imageNetACustomNames\n",
    "        mapping = imageNetAMap\n",
    "    else:\n",
    "        dataset = imageNetV2\n",
    "        classnames = imageNetV2CustomNames\n",
    "        mapping = imageNetV2Map\n",
    "    \n",
    "    tpt = EasyTPT(\n",
    "        base_prompt=base_prompt,\n",
    "        arch=arch,\n",
    "        splt_ctx=splt_ctx,\n",
    "        classnames=classnames,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return tpt, dataset, mapping\n",
    "\n",
    "def memo(device=\"cuda\", prior_strength=0.94, naug=30, A=True):\n",
    "    # prepare MEMO\n",
    "    imageNet_A, imageNet_V2 = memo_get_datasets(augmentation='cut', augs=naug)\n",
    "    dataset = imageNet_A if A else imageNet_V2\n",
    "\n",
    "    mapping = list(dataset.classnames.keys())\n",
    "    for i,id in enumerate(mapping):\n",
    "        mapping[i] = int(id)\n",
    "    \n",
    "    rn50 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    memo = EasyMemo(rn50, device=device, classes_mask=mapping, prior_strength=prior_strength)\n",
    "    \n",
    "    return memo, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tpt_model:EasyTPT, memo_model, tpt_data, mapping, memo_data, device=\"cuda\", niter=1, top=0.1, no_backwards=False, testSingleModels=False):\n",
    "    correct = 0\n",
    "    correct_no_back = 0\n",
    "    correctSingle = [0, 0]\n",
    "    cnt = 0\n",
    "\n",
    "    class_names = get_classes_names()\n",
    "    models_names = [\"TPT\", \"MEMO\"]\n",
    "\n",
    "    TPT_temp = 1.55\n",
    "    MEMO_temp = 0.7\n",
    "    temps = [TPT_temp, MEMO_temp]\n",
    "\n",
    "    #shuffle the data\n",
    "    indx = np.random.permutation(range(len(tpt_data)))\n",
    "\n",
    "    model = Ensemble(models=[tpt_model, memo_model], temps=temps, \n",
    "                     device=device, test_single_models=testSingleModels, \n",
    "                     no_backwards=no_backwards)\n",
    "    print(\"Ensemble model created starting TTA, samples:\",len(indx))\n",
    "    for i in indx:\n",
    "        cnt += 1 \n",
    "        img_TPT = tpt_data[i][\"img\"]\n",
    "        img_MEMO = memo_data[i][\"img\"]\n",
    "        data = [img_TPT, img_MEMO]\n",
    "        \n",
    "        label = int(tpt_data[i][\"label\"])\n",
    "        label2 = int(memo_data[i][\"label\"])\n",
    "        assert label == label2 #check if the labels are the same\n",
    "        name = tpt_data[i][\"name\"]\n",
    "\n",
    "        print (f\"Testing on {i} - name: {name} - label: {label}\")\n",
    "\n",
    "        models_out, pred_no_back, prediction = model(data, niter=niter, top=0.1)\n",
    "        models_out = [int(mapping[model_out]) for model_out in models_out]\n",
    "        prediction = int(mapping[prediction])\n",
    "        \n",
    "        if testSingleModels:\n",
    "            for i, model_out in enumerate(models_out):\n",
    "                if label == model_out:\n",
    "                    correctSingle[i] += 1\n",
    "                \n",
    "                print(f\"\\t{models_names[i]} model accuracy: {correctSingle[i]}/{cnt} - predicted class {model_out}: {class_names[model_out]} - tested: {cnt} / {len(tpt_data)}\")\n",
    "\n",
    "        if no_backwards:\n",
    "            pred_no_back = int(mapping[pred_no_back])\n",
    "            if label == pred_no_back:\n",
    "                correct_no_back += 1\n",
    "            print(f\"\\tSimple Ens accuracy: {correct_no_back}/{cnt} - predicted class {pred_no_back}: {class_names[pred_no_back]} - tested: {cnt} / {len(tpt_data)}\")\n",
    "\n",
    "        if label == prediction:\n",
    "            correct += 1\n",
    "            \n",
    "        print(f\"\\tEnsemble accuracy: {correct}/{cnt} - predicted class {prediction}: {class_names[prediction]} - tested: {cnt} / {len(tpt_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU, brace yourself!\n",
      "[PromptLearner] Preparing prompts\n",
      "[EasyTPT] Training parameter: prompt_learner.emb_prefix\n",
      "[EasyTPT] Training parameter: prompt_learner.emb_suffix\n",
      "modifying BN forward pass\n",
      "Testing on ImageNet-A\n",
      "Ensemble model created starting TTA, samples: 7500\n",
      "Testing on 641 - name: eft - label: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12305/3765224167.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t[Ensemble] Entropies:  tensor([1.6317, 2.3735], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5926, 0.4074], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([0.9218, 0.3971], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3011, 0.6989], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.6317, 2.3735], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5926, 0.4074], device='cuda:0')\n",
      "\tTPT model accuracy: 0/1 - predicted class 57: garter snake, grass snake - tested: 1 / 7500\n",
      "\tMEMO model accuracy: 1/1 - predicted class 27: eft - tested: 1 / 7500\n",
      "\tSimple Ens accuracy (no back): 0/1 - predicted class 57: garter snake, grass snake - tested: 1 / 7500\n",
      "\tEnsemble accuracy: 0/1 - predicted class 79: centipede - tested: 1 / 7500\n",
      "Testing on 3787 - name: cockroach, roach - label: 314\n",
      "\t\t[Ensemble] Entropies:  tensor([4.3946, 2.1879], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3324, 0.6676], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8439, 0.0039], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0010, 0.9990], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.3946, 2.1879], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3324, 0.6676], device='cuda:0')\n",
      "\tTPT model accuracy: 0/2 - predicted class 124: crayfish, crawfish, crawdad, crawdaddy - tested: 2 / 7500\n",
      "\tMEMO model accuracy: 1/2 - predicted class 947: mushroom - tested: 2 / 7500\n",
      "\tSimple Ens accuracy (no back): 0/2 - predicted class 110: flatworm, platyhelminth - tested: 2 / 7500\n",
      "\tEnsemble accuracy: 0/2 - predicted class 327: starfish, sea star - tested: 2 / 7500\n",
      "Testing on 6114 - name: puck, hockey puck - label: 746\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4245, 0.1366], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0383, 0.9617], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.4376e+00, 2.4928e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.7337e-04, 9.9983e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4245, 0.1366], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0383, 0.9617], device='cuda:0')\n",
      "\tTPT model accuracy: 0/3 - predicted class 792: shovel - tested: 3 / 7500\n",
      "\tMEMO model accuracy: 1/3 - predicted class 792: shovel - tested: 3 / 7500\n",
      "\tSimple Ens accuracy (no back): 0/3 - predicted class 792: shovel - tested: 3 / 7500\n",
      "\tEnsemble accuracy: 0/3 - predicted class 792: shovel - tested: 3 / 7500\n",
      "Testing on 7327 - name: pomegranate - label: 957\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8631, 0.6234], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1390, 0.8610], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8457e+00, 2.2621e-14], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([7.9493e-15, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8631, 0.6234], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1390, 0.8610], device='cuda:0')\n",
      "\tTPT model accuracy: 1/4 - predicted class 957: pomegranate - tested: 4 / 7500\n",
      "\tMEMO model accuracy: 1/4 - predicted class 934: hotdog, hot dog, red hot - tested: 4 / 7500\n",
      "\tSimple Ens accuracy (no back): 0/4 - predicted class 934: hotdog, hot dog, red hot - tested: 4 / 7500\n",
      "\tEnsemble accuracy: 0/4 - predicted class 934: hotdog, hot dog, red hot - tested: 4 / 7500\n",
      "Testing on 3841 - name: cockroach, roach - label: 314\n",
      "\t\t[Ensemble] Entropies:  tensor([3.5639, 3.4838], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4943, 0.5057], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8689, 1.0453], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2671, 0.7329], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.5639, 3.4838], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4943, 0.5057], device='cuda:0')\n",
      "\tTPT model accuracy: 2/5 - predicted class 314: cockroach, roach - tested: 5 / 7500\n",
      "\tMEMO model accuracy: 1/5 - predicted class 626: lighter, light, igniter, ignitor - tested: 5 / 7500\n",
      "\tSimple Ens accuracy (no back): 1/5 - predicted class 314: cockroach, roach - tested: 5 / 7500\n",
      "\tEnsemble accuracy: 0/5 - predicted class 677: nail - tested: 5 / 7500\n",
      "Testing on 4331 - name: wood rabbit, cottontail, cottontail rabbit - label: 330\n",
      "\t\t[Ensemble] Entropies:  tensor([3.7578, 3.0162], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4453, 0.5547], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.1896e+00, 6.8585e-07], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.6370e-07, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.7578, 3.0162], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4453, 0.5547], device='cuda:0')\n",
      "\tTPT model accuracy: 2/6 - predicted class 143: oystercatcher, oyster catcher - tested: 6 / 7500\n",
      "\tMEMO model accuracy: 1/6 - predicted class 569: garbage truck, dustcart - tested: 6 / 7500\n",
      "\tSimple Ens accuracy (no back): 1/6 - predicted class 569: garbage truck, dustcart - tested: 6 / 7500\n",
      "\tEnsemble accuracy: 0/6 - predicted class 569: garbage truck, dustcart - tested: 6 / 7500\n",
      "Testing on 1682 - name: hummingbird - label: 94\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1555, 0.6841], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1782, 0.8218], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4519e+00, 6.9529e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.0138e-04, 9.9980e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1555, 0.6841], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1782, 0.8218], device='cuda:0')\n",
      "\tTPT model accuracy: 2/7 - predicted class 13: junco, snowbird - tested: 7 / 7500\n",
      "\tMEMO model accuracy: 1/7 - predicted class 804: soap dispenser - tested: 7 / 7500\n",
      "\tSimple Ens accuracy (no back): 2/7 - predicted class 94: hummingbird - tested: 7 / 7500\n",
      "\tEnsemble accuracy: 1/7 - predicted class 94: hummingbird - tested: 7 / 7500\n",
      "Testing on 1257 - name: harvestman, daddy longlegs, Phalangium opilio - label: 70\n",
      "\t\t[Ensemble] Entropies:  tensor([4.1712, 0.9991], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1932, 0.8068], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9338e+00, 6.6599e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.6927e-04, 9.9983e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.1712, 0.9991], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1932, 0.8068], device='cuda:0')\n",
      "\tTPT model accuracy: 2/8 - predicted class 971: bubble - tested: 8 / 7500\n",
      "\tMEMO model accuracy: 1/8 - predicted class 310: ant, emmet, pismire - tested: 8 / 7500\n",
      "\tSimple Ens accuracy (no back): 3/8 - predicted class 70: harvestman, daddy longlegs, Phalangium opilio - tested: 8 / 7500\n",
      "\tEnsemble accuracy: 2/8 - predicted class 70: harvestman, daddy longlegs, Phalangium opilio - tested: 8 / 7500\n",
      "Testing on 3877 - name: mantis, mantid - label: 315\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9408, 0.4676], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1061, 0.8939], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.1796e+00, 7.2088e-07], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.7247e-07, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9408, 0.4676], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1061, 0.8939], device='cuda:0')\n",
      "\tTPT model accuracy: 2/9 - predicted class 334: porcupine, hedgehog - tested: 9 / 7500\n",
      "\tMEMO model accuracy: 1/9 - predicted class 313: walking stick, walkingstick, stick insect - tested: 9 / 7500\n",
      "\tSimple Ens accuracy (no back): 3/9 - predicted class 334: porcupine, hedgehog - tested: 9 / 7500\n",
      "\tEnsemble accuracy: 2/9 - predicted class 334: porcupine, hedgehog - tested: 9 / 7500\n",
      "Testing on 700 - name: bullfrog, Rana catesbeiana - label: 30\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6173, 2.2870], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3873, 0.6127], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9318, 0.8653], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1804, 0.8196], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6173, 2.2870], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3873, 0.6127], device='cuda:0')\n",
      "\tTPT model accuracy: 2/10 - predicted class 314: cockroach, roach - tested: 10 / 7500\n",
      "\tMEMO model accuracy: 1/10 - predicted class 307: weevil - tested: 10 / 7500\n",
      "\tSimple Ens accuracy (no back): 3/10 - predicted class 306: rhinoceros beetle - tested: 10 / 7500\n",
      "\tEnsemble accuracy: 3/10 - predicted class 30: bullfrog, Rana catesbeiana - tested: 10 / 7500\n",
      "Testing on 4286 - name: lycaenid, lycaenid butterfly - label: 326\n",
      "\t\t[Ensemble] Entropies:  tensor([3.5240, 1.0972], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2374, 0.7626], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.6869e+00, 9.5018e-07], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([3.5364e-07, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.5240, 1.0972], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2374, 0.7626], device='cuda:0')\n",
      "\tTPT model accuracy: 2/11 - predicted class 324: cabbage butterfly - tested: 11 / 7500\n",
      "\tMEMO model accuracy: 2/11 - predicted class 326: lycaenid, lycaenid butterfly - tested: 11 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/11 - predicted class 326: lycaenid, lycaenid butterfly - tested: 11 / 7500\n",
      "\tEnsemble accuracy: 4/11 - predicted class 326: lycaenid, lycaenid butterfly - tested: 11 / 7500\n",
      "Testing on 7292 - name: pomegranate - label: 957\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0579, 2.4168], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3733, 0.6267], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.0466e+00, 1.4741e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([4.8382e-05, 9.9995e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0579, 2.4168], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3733, 0.6267], device='cuda:0')\n",
      "\tTPT model accuracy: 2/12 - predicted class 470: candle, taper, wax light - tested: 12 / 7500\n",
      "\tMEMO model accuracy: 2/12 - predicted class 907: wine bottle - tested: 12 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/12 - predicted class 945: bell pepper - tested: 12 / 7500\n",
      "\tEnsemble accuracy: 4/12 - predicted class 945: bell pepper - tested: 12 / 7500\n",
      "Testing on 6264 - name: sandal - label: 774\n",
      "\t\t[Ensemble] Entropies:  tensor([1.6171, 0.1607], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0904, 0.9096], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([5.2934e-01, 1.6763e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([3.1659e-04, 9.9968e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.6171, 0.1607], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0904, 0.9096], device='cuda:0')\n",
      "\tTPT model accuracy: 2/13 - predicted class 411: apron - tested: 13 / 7500\n",
      "\tMEMO model accuracy: 2/13 - predicted class 411: apron - tested: 13 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/13 - predicted class 411: apron - tested: 13 / 7500\n",
      "\tEnsemble accuracy: 4/13 - predicted class 411: apron - tested: 13 / 7500\n",
      "Testing on 536 - name: vulture - label: 23\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6058, 2.5541], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4146, 0.5854], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1063e+00, 9.0926e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.9263e-04, 9.9971e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6058, 2.5541], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4146, 0.5854], device='cuda:0')\n",
      "\tTPT model accuracy: 3/14 - predicted class 23: vulture - tested: 14 / 7500\n",
      "\tMEMO model accuracy: 2/14 - predicted class 888: viaduct - tested: 14 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/14 - predicted class 888: viaduct - tested: 14 / 7500\n",
      "\tEnsemble accuracy: 4/14 - predicted class 888: viaduct - tested: 14 / 7500\n",
      "Testing on 2011 - name: jellyfish - label: 107\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9464, 0.2548], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0607, 0.9393], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7901e+00, 1.9302e-03], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([6.9133e-04, 9.9931e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9464, 0.2548], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0607, 0.9393], device='cuda:0')\n",
      "\tTPT model accuracy: 4/15 - predicted class 107: jellyfish - tested: 15 / 7500\n",
      "\tMEMO model accuracy: 2/15 - predicted class 125: hermit crab - tested: 15 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/15 - predicted class 125: hermit crab - tested: 15 / 7500\n",
      "\tEnsemble accuracy: 4/15 - predicted class 125: hermit crab - tested: 15 / 7500\n",
      "Testing on 1171 - name: garter snake, grass snake - label: 57\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4041, 2.9693], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4659, 0.5341], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1417e+00, 1.4920e-05], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([6.9664e-06, 9.9999e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4041, 2.9693], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4659, 0.5341], device='cuda:0')\n",
      "\tTPT model accuracy: 4/16 - predicted class 472: canoe - tested: 16 / 7500\n",
      "\tMEMO model accuracy: 2/16 - predicted class 847: tank, army tank, armored combat vehicle, armoured combat vehicle - tested: 16 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/16 - predicted class 472: canoe - tested: 16 / 7500\n",
      "\tEnsemble accuracy: 4/16 - predicted class 847: tank, army tank, armored combat vehicle, armoured combat vehicle - tested: 16 / 7500\n",
      "Testing on 1043 - name: African chameleon, Chamaeleo chamaeleon - label: 47\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1365, 1.6436], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4348, 0.5652], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.4925e+00, 5.7959e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.3247e-04, 9.9977e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1365, 1.6436], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4348, 0.5652], device='cuda:0')\n",
      "\tTPT model accuracy: 4/17 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 17 / 7500\n",
      "\tMEMO model accuracy: 2/17 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 17 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/17 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 17 / 7500\n",
      "\tEnsemble accuracy: 4/17 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 17 / 7500\n",
      "Testing on 4643 - name: skunk, polecat, wood pussy - label: 361\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6544, 3.2469], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4705, 0.5295], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.2332, 2.6049], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5384, 0.4616], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6544, 3.2469], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4705, 0.5295], device='cuda:0')\n",
      "\tTPT model accuracy: 4/18 - predicted class 23: vulture - tested: 18 / 7500\n",
      "\tMEMO model accuracy: 2/18 - predicted class 363: armadillo - tested: 18 / 7500\n",
      "\tSimple Ens accuracy (no back): 4/18 - predicted class 23: vulture - tested: 18 / 7500\n",
      "\tEnsemble accuracy: 4/18 - predicted class 23: vulture - tested: 18 / 7500\n",
      "Testing on 1334 - name: scorpion - label: 71\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8532, 0.4997], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1490, 0.8510], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1390e+00, 1.2364e-03], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([5.7772e-04, 9.9942e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8532, 0.4997], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1490, 0.8510], device='cuda:0')\n",
      "\tTPT model accuracy: 5/19 - predicted class 71: scorpion - tested: 19 / 7500\n",
      "\tMEMO model accuracy: 3/19 - predicted class 71: scorpion - tested: 19 / 7500\n",
      "\tSimple Ens accuracy (no back): 5/19 - predicted class 71: scorpion - tested: 19 / 7500\n",
      "\tEnsemble accuracy: 5/19 - predicted class 71: scorpion - tested: 19 / 7500\n",
      "Testing on 2861 - name: red fox, Vulpes vulpes - label: 277\n",
      "\t\t[Ensemble] Entropies:  tensor([4.2197, 3.3476], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4424, 0.5576], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9344, 0.0464], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0117, 0.9883], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.2197, 3.3476], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4424, 0.5576], device='cuda:0')\n",
      "\tTPT model accuracy: 5/20 - predicted class 11: goldfinch, Carduelis carduelis - tested: 20 / 7500\n",
      "\tMEMO model accuracy: 3/20 - predicted class 428: barrow, garden cart, lawn cart, wheelbarrow - tested: 20 / 7500\n",
      "\tSimple Ens accuracy (no back): 5/20 - predicted class 428: barrow, garden cart, lawn cart, wheelbarrow - tested: 20 / 7500\n",
      "\tEnsemble accuracy: 5/20 - predicted class 428: barrow, garden cart, lawn cart, wheelbarrow - tested: 20 / 7500\n",
      "Testing on 6990 - name: wreck - label: 913\n",
      "\t\t[Ensemble] Entropies:  tensor([2.6553, 0.6351], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1930, 0.8070], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.2463e+00, 1.5416e-03], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([6.8585e-04, 9.9931e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.6553, 0.6351], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1930, 0.8070], device='cuda:0')\n",
      "\tTPT model accuracy: 6/21 - predicted class 913: wreck - tested: 21 / 7500\n",
      "\tMEMO model accuracy: 3/21 - predicted class 802: snowmobile - tested: 21 / 7500\n",
      "\tSimple Ens accuracy (no back): 5/21 - predicted class 802: snowmobile - tested: 21 / 7500\n",
      "\tEnsemble accuracy: 5/21 - predicted class 802: snowmobile - tested: 21 / 7500\n",
      "Testing on 3816 - name: cockroach, roach - label: 314\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4254, 1.3471], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2823, 0.7177], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0972, 3.5681], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4655, 0.5345], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4254, 1.3471], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2823, 0.7177], device='cuda:0')\n",
      "\tTPT model accuracy: 7/22 - predicted class 314: cockroach, roach - tested: 22 / 7500\n",
      "\tMEMO model accuracy: 4/22 - predicted class 314: cockroach, roach - tested: 22 / 7500\n",
      "\tSimple Ens accuracy (no back): 6/22 - predicted class 314: cockroach, roach - tested: 22 / 7500\n",
      "\tEnsemble accuracy: 6/22 - predicted class 314: cockroach, roach - tested: 22 / 7500\n",
      "Testing on 3427 - name: fly - label: 308\n",
      "\t\t[Ensemble] Entropies:  tensor([3.2177, 0.2610], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0750, 0.9250], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.2517e+00, 1.2302e-06], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.8935e-07, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.2177, 0.2610], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0750, 0.9250], device='cuda:0')\n",
      "\tTPT model accuracy: 7/23 - predicted class 932: pretzel - tested: 23 / 7500\n",
      "\tMEMO model accuracy: 4/23 - predicted class 932: pretzel - tested: 23 / 7500\n",
      "\tSimple Ens accuracy (no back): 6/23 - predicted class 932: pretzel - tested: 23 / 7500\n",
      "\tEnsemble accuracy: 6/23 - predicted class 932: pretzel - tested: 23 / 7500\n",
      "Testing on 883 - name: common iguana, iguana, Iguana iguana - label: 39\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8961, 0.1504], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0494, 0.9506], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.1194, 0.0108], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0026, 0.9974], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8961, 0.1504], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0494, 0.9506], device='cuda:0')\n",
      "\tTPT model accuracy: 7/24 - predicted class 378: capuchin, ringtail, Cebus capucinus - tested: 24 / 7500\n",
      "\tMEMO model accuracy: 5/24 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 24 / 7500\n",
      "\tSimple Ens accuracy (no back): 7/24 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 24 / 7500\n",
      "\tEnsemble accuracy: 7/24 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 24 / 7500\n",
      "Testing on 2639 - name: American egret, great white heron, Egretta albus - label: 132\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4352, 3.5563], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5087, 0.4913], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7416, 0.1190], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0416, 0.9584], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4352, 3.5563], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5087, 0.4913], device='cuda:0')\n",
      "\tTPT model accuracy: 7/25 - predicted class 11: goldfinch, Carduelis carduelis - tested: 25 / 7500\n",
      "\tMEMO model accuracy: 5/25 - predicted class 99: goose - tested: 25 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/25 - predicted class 132: American egret, great white heron, Egretta albus - tested: 25 / 7500\n",
      "\tEnsemble accuracy: 8/25 - predicted class 132: American egret, great white heron, Egretta albus - tested: 25 / 7500\n",
      "Testing on 69 - name: stingray - label: 6\n",
      "\t\t[Ensemble] Entropies:  tensor([2.5987, 2.1205], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4493, 0.5507], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.0733e+00, 2.7792e-03], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([9.0350e-04, 9.9910e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.5987, 2.1205], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4493, 0.5507], device='cuda:0')\n",
      "\tTPT model accuracy: 8/26 - predicted class 6: stingray - tested: 26 / 7500\n",
      "\tMEMO model accuracy: 5/26 - predicted class 143: oystercatcher, oyster catcher - tested: 26 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/26 - predicted class 143: oystercatcher, oyster catcher - tested: 26 / 7500\n",
      "\tEnsemble accuracy: 8/26 - predicted class 143: oystercatcher, oyster catcher - tested: 26 / 7500\n",
      "Testing on 5068 - name: beaker - label: 438\n",
      "\t\t[Ensemble] Entropies:  tensor([2.4904, 2.1212], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4600, 0.5400], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.0625e+00, 3.6100e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.7500e-04, 9.9983e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.4904, 2.1212], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4600, 0.5400], device='cuda:0')\n",
      "\tTPT model accuracy: 8/27 - predicted class 470: candle, taper, wax light - tested: 27 / 7500\n",
      "\tMEMO model accuracy: 5/27 - predicted class 572: goblet - tested: 27 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/27 - predicted class 470: candle, taper, wax light - tested: 27 / 7500\n",
      "\tEnsemble accuracy: 8/27 - predicted class 470: candle, taper, wax light - tested: 27 / 7500\n",
      "Testing on 6986 - name: wine bottle - label: 907\n",
      "\t\t[Ensemble] Entropies:  tensor([0.7153, 0.0575], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0744, 0.9256], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.0938, 0.0016], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0015, 0.9985], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([0.7153, 0.0575], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0744, 0.9256], device='cuda:0')\n",
      "\tTPT model accuracy: 8/28 - predicted class 758: reel - tested: 28 / 7500\n",
      "\tMEMO model accuracy: 5/28 - predicted class 758: reel - tested: 28 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/28 - predicted class 758: reel - tested: 28 / 7500\n",
      "\tEnsemble accuracy: 8/28 - predicted class 758: reel - tested: 28 / 7500\n",
      "Testing on 5112 - name: bow - label: 456\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9800, 0.3734], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0858, 0.9142], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.6323e+00, 6.1769e-06], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.3466e-06, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9800, 0.3734], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0858, 0.9142], device='cuda:0')\n",
      "\tTPT model accuracy: 8/29 - predicted class 416: balance beam, beam - tested: 29 / 7500\n",
      "\tMEMO model accuracy: 5/29 - predicted class 462: broom - tested: 29 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/29 - predicted class 462: broom - tested: 29 / 7500\n",
      "\tEnsemble accuracy: 8/29 - predicted class 462: broom - tested: 29 / 7500\n",
      "Testing on 2330 - name: snail - label: 113\n",
      "\t\t[Ensemble] Entropies:  tensor([3.2565, 2.5876], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4428, 0.5572], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.3285, 0.5431], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1403, 0.8597], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.2565, 2.5876], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4428, 0.5572], device='cuda:0')\n",
      "\tTPT model accuracy: 8/30 - predicted class 314: cockroach, roach - tested: 30 / 7500\n",
      "\tMEMO model accuracy: 5/30 - predicted class 314: cockroach, roach - tested: 30 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/30 - predicted class 314: cockroach, roach - tested: 30 / 7500\n",
      "\tEnsemble accuracy: 9/30 - predicted class 113: snail - tested: 30 / 7500\n",
      "Testing on 7002 - name: guacamole - label: 924\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8690, 3.9009], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5021, 0.4979], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8721, 0.1490], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0371, 0.9629], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8690, 3.9009], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5021, 0.4979], device='cuda:0')\n",
      "\tTPT model accuracy: 8/31 - predicted class 47: African chameleon, Chamaeleo chamaeleon - tested: 31 / 7500\n",
      "\tMEMO model accuracy: 5/31 - predicted class 47: African chameleon, Chamaeleo chamaeleon - tested: 31 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/31 - predicted class 47: African chameleon, Chamaeleo chamaeleon - tested: 31 / 7500\n",
      "\tEnsemble accuracy: 9/31 - predicted class 47: African chameleon, Chamaeleo chamaeleon - tested: 31 / 7500\n",
      "Testing on 2969 - name: Persian cat - label: 283\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9422, 1.8358], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3177, 0.6823], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4539e+00, 9.4938e-07], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.7487e-07, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9422, 1.8358], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3177, 0.6823], device='cuda:0')\n",
      "\tTPT model accuracy: 8/32 - predicted class 765: rocking chair, rocker - tested: 32 / 7500\n",
      "\tMEMO model accuracy: 5/32 - predicted class 765: rocking chair, rocker - tested: 32 / 7500\n",
      "\tSimple Ens accuracy (no back): 8/32 - predicted class 765: rocking chair, rocker - tested: 32 / 7500\n",
      "\tEnsemble accuracy: 9/32 - predicted class 552: feather boa, boa - tested: 32 / 7500\n",
      "Testing on 905 - name: common iguana, iguana, Iguana iguana - label: 39\n",
      "\t\t[Ensemble] Entropies:  tensor([2.9262, 0.1524], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0495, 0.9505], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.2770, 0.0065], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0020, 0.9980], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.9262, 0.1524], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0495, 0.9505], device='cuda:0')\n",
      "\tTPT model accuracy: 9/33 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 33 / 7500\n",
      "\tMEMO model accuracy: 6/33 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 33 / 7500\n",
      "\tSimple Ens accuracy (no back): 9/33 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 33 / 7500\n",
      "\tEnsemble accuracy: 10/33 - predicted class 39: common iguana, iguana, Iguana iguana - tested: 33 / 7500\n",
      "Testing on 1557 - name: sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita - label: 89\n",
      "\t\t[Ensemble] Entropies:  tensor([1.5780, 1.0723], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4046, 0.5954], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.1091e+00, 5.6482e-06], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([5.0925e-06, 9.9999e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.5780, 1.0723], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4046, 0.5954], device='cuda:0')\n",
      "\tTPT model accuracy: 10/34 - predicted class 89: sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita - tested: 34 / 7500\n",
      "\tMEMO model accuracy: 6/34 - predicted class 372: baboon - tested: 34 / 7500\n",
      "\tSimple Ens accuracy (no back): 10/34 - predicted class 89: sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita - tested: 34 / 7500\n",
      "\tEnsemble accuracy: 11/34 - predicted class 89: sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita - tested: 34 / 7500\n",
      "Testing on 5607 - name: goblet - label: 572\n",
      "\t\t[Ensemble] Entropies:  tensor([1.3953, 0.0418], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0291, 0.9709], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.7255, 0.0019], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0011, 0.9989], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.3953, 0.0418], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0291, 0.9709], device='cuda:0')\n",
      "\tTPT model accuracy: 10/35 - predicted class 643: mask - tested: 35 / 7500\n",
      "\tMEMO model accuracy: 6/35 - predicted class 643: mask - tested: 35 / 7500\n",
      "\tSimple Ens accuracy (no back): 10/35 - predicted class 643: mask - tested: 35 / 7500\n",
      "\tEnsemble accuracy: 11/35 - predicted class 643: mask - tested: 35 / 7500\n",
      "Testing on 2422 - name: crayfish, crawfish, crawdad, crawdaddy - label: 124\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7058, 1.6604], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3803, 0.6197], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.9894e+00, 5.3255e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([2.6762e-04, 9.9973e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7058, 1.6604], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3803, 0.6197], device='cuda:0')\n",
      "\tTPT model accuracy: 11/36 - predicted class 124: crayfish, crawfish, crawdad, crawdaddy - tested: 36 / 7500\n",
      "\tMEMO model accuracy: 6/36 - predicted class 319: dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk - tested: 36 / 7500\n",
      "\tSimple Ens accuracy (no back): 11/36 - predicted class 124: crayfish, crawfish, crawdad, crawdaddy - tested: 36 / 7500\n",
      "\tEnsemble accuracy: 12/36 - predicted class 124: crayfish, crawfish, crawdad, crawdaddy - tested: 36 / 7500\n",
      "Testing on 2356 - name: snail - label: 113\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8259, 0.3602], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1131, 0.8869], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1966e+00, 1.4865e-03], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([6.7629e-04, 9.9932e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8259, 0.3602], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1131, 0.8869], device='cuda:0')\n",
      "\tTPT model accuracy: 12/37 - predicted class 113: snail - tested: 37 / 7500\n",
      "\tMEMO model accuracy: 7/37 - predicted class 113: snail - tested: 37 / 7500\n",
      "\tSimple Ens accuracy (no back): 12/37 - predicted class 113: snail - tested: 37 / 7500\n",
      "\tEnsemble accuracy: 13/37 - predicted class 113: snail - tested: 37 / 7500\n",
      "Testing on 5767 - name: kimono - label: 614\n",
      "\t\t[Ensemble] Entropies:  tensor([3.3147, 1.0562], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2416, 0.7584], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.5000e+00, 2.8833e-07], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([8.2381e-08, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.3147, 1.0562], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2416, 0.7584], device='cuda:0')\n",
      "\tTPT model accuracy: 13/38 - predicted class 614: kimono - tested: 38 / 7500\n",
      "\tMEMO model accuracy: 7/38 - predicted class 461: breastplate, aegis, egis - tested: 38 / 7500\n",
      "\tSimple Ens accuracy (no back): 12/38 - predicted class 461: breastplate, aegis, egis - tested: 38 / 7500\n",
      "\tEnsemble accuracy: 13/38 - predicted class 461: breastplate, aegis, egis - tested: 38 / 7500\n",
      "Testing on 4823 - name: ambulance - label: 407\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1927, 0.8042], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2684, 0.7316], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1857, 2.2200], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5039, 0.4961], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1927, 0.8042], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2684, 0.7316], device='cuda:0')\n",
      "\tTPT model accuracy: 13/39 - predicted class 486: cello, violoncello - tested: 39 / 7500\n",
      "\tMEMO model accuracy: 7/39 - predicted class 486: cello, violoncello - tested: 39 / 7500\n",
      "\tSimple Ens accuracy (no back): 13/39 - predicted class 407: ambulance - tested: 39 / 7500\n",
      "\tEnsemble accuracy: 13/39 - predicted class 486: cello, violoncello - tested: 39 / 7500\n",
      "Testing on 2044 - name: jellyfish - label: 107\n",
      "\t\t[Ensemble] Entropies:  tensor([3.0175, 1.2497], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2929, 0.7071], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.4452e+00, 4.1710e-11], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.7058e-11, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.0175, 1.2497], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2929, 0.7071], device='cuda:0')\n",
      "\tTPT model accuracy: 13/40 - predicted class 6: stingray - tested: 40 / 7500\n",
      "\tMEMO model accuracy: 7/40 - predicted class 110: flatworm, platyhelminth - tested: 40 / 7500\n",
      "\tSimple Ens accuracy (no back): 13/40 - predicted class 110: flatworm, platyhelminth - tested: 40 / 7500\n",
      "\tEnsemble accuracy: 13/40 - predicted class 110: flatworm, platyhelminth - tested: 40 / 7500\n",
      "Testing on 3441 - name: fly - label: 308\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8030, 0.8591], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1843, 0.8157], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.5596e+00, 3.6167e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([1.4128e-04, 9.9986e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8030, 0.8591], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1843, 0.8157], device='cuda:0')\n",
      "\tTPT model accuracy: 13/41 - predicted class 972: cliff, drop, drop-off - tested: 41 / 7500\n",
      "\tMEMO model accuracy: 7/41 - predicted class 306: rhinoceros beetle - tested: 41 / 7500\n",
      "\tSimple Ens accuracy (no back): 13/41 - predicted class 972: cliff, drop, drop-off - tested: 41 / 7500\n",
      "\tEnsemble accuracy: 13/41 - predicted class 972: cliff, drop, drop-off - tested: 41 / 7500\n",
      "Testing on 6871 - name: volleyball - label: 890\n",
      "\t\t[Ensemble] Entropies:  tensor([2.3946, 0.0706], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0286, 0.9714], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.3565, 0.0055], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0023, 0.9977], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.3946, 0.0706], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0286, 0.9714], device='cuda:0')\n",
      "\tTPT model accuracy: 13/42 - predicted class 557: flagpole, flagstaff - tested: 42 / 7500\n",
      "\tMEMO model accuracy: 7/42 - predicted class 557: flagpole, flagstaff - tested: 42 / 7500\n",
      "\tSimple Ens accuracy (no back): 13/42 - predicted class 557: flagpole, flagstaff - tested: 42 / 7500\n",
      "\tEnsemble accuracy: 13/42 - predicted class 557: flagpole, flagstaff - tested: 42 / 7500\n",
      "Testing on 1985 - name: koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus - label: 105\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1018, 0.2928], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0862, 0.9138], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.4204, 0.0058], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0024, 0.9976], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1018, 0.2928], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0862, 0.9138], device='cuda:0')\n",
      "\tTPT model accuracy: 14/43 - predicted class 105: koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus - tested: 43 / 7500\n",
      "\tMEMO model accuracy: 7/43 - predicted class 334: porcupine, hedgehog - tested: 43 / 7500\n",
      "\tSimple Ens accuracy (no back): 14/43 - predicted class 105: koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus - tested: 43 / 7500\n",
      "\tEnsemble accuracy: 14/43 - predicted class 105: koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus - tested: 43 / 7500\n",
      "Testing on 5544 - name: flagpole, flagstaff - label: 557\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8170, 3.4703], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4762, 0.5238], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.9243, 0.0060], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0015, 0.9985], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8170, 3.4703], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4762, 0.5238], device='cuda:0')\n",
      "\tTPT model accuracy: 15/44 - predicted class 557: flagpole, flagstaff - tested: 44 / 7500\n",
      "\tMEMO model accuracy: 7/44 - predicted class 786: sewing machine - tested: 44 / 7500\n",
      "\tSimple Ens accuracy (no back): 15/44 - predicted class 557: flagpole, flagstaff - tested: 44 / 7500\n",
      "\tEnsemble accuracy: 14/44 - predicted class 401: accordion, piano accordion, squeeze box - tested: 44 / 7500\n",
      "Testing on 1299 - name: scorpion - label: 71\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1680, 0.3440], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0980, 0.9020], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.3069, 0.0063], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0019, 0.9981], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1680, 0.3440], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0980, 0.9020], device='cuda:0')\n",
      "\tTPT model accuracy: 15/45 - predicted class 314: cockroach, roach - tested: 45 / 7500\n",
      "\tMEMO model accuracy: 8/45 - predicted class 71: scorpion - tested: 45 / 7500\n",
      "\tSimple Ens accuracy (no back): 16/45 - predicted class 71: scorpion - tested: 45 / 7500\n",
      "\tEnsemble accuracy: 15/45 - predicted class 71: scorpion - tested: 45 / 7500\n",
      "Testing on 3270 - name: ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle - label: 301\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7200, 2.3429], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4628, 0.5372], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6279, 0.0307], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0084, 0.9916], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7200, 2.3429], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4628, 0.5372], device='cuda:0')\n",
      "\tTPT model accuracy: 16/46 - predicted class 301: ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle - tested: 46 / 7500\n",
      "\tMEMO model accuracy: 8/46 - predicted class 626: lighter, light, igniter, ignitor - tested: 46 / 7500\n",
      "\tSimple Ens accuracy (no back): 17/46 - predicted class 301: ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle - tested: 46 / 7500\n",
      "\tEnsemble accuracy: 16/46 - predicted class 301: ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle - tested: 46 / 7500\n",
      "Testing on 4551 - name: marmot - label: 336\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1764, 0.3310], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0944, 0.9056], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.2232e+00, 4.0371e-06], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([3.3005e-06, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1764, 0.3310], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0944, 0.9056], device='cuda:0')\n",
      "\tTPT model accuracy: 16/47 - predicted class 890: volleyball - tested: 47 / 7500\n",
      "\tMEMO model accuracy: 8/47 - predicted class 96: toucan - tested: 47 / 7500\n",
      "\tSimple Ens accuracy (no back): 17/47 - predicted class 96: toucan - tested: 47 / 7500\n",
      "\tEnsemble accuracy: 16/47 - predicted class 96: toucan - tested: 47 / 7500\n",
      "Testing on 1831 - name: drake - label: 97\n",
      "\t\t[Ensemble] Entropies:  tensor([1.7672, 3.2477], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6476, 0.3524], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.5024, 3.5197], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5845, 0.4155], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.7672, 3.2477], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6476, 0.3524], device='cuda:0')\n",
      "\tTPT model accuracy: 17/48 - predicted class 97: drake - tested: 48 / 7500\n",
      "\tMEMO model accuracy: 8/48 - predicted class 15: robin, American robin, Turdus migratorius - tested: 48 / 7500\n",
      "\tSimple Ens accuracy (no back): 18/48 - predicted class 97: drake - tested: 48 / 7500\n",
      "\tEnsemble accuracy: 16/48 - predicted class 562: fountain - tested: 48 / 7500\n",
      "Testing on 5818 - name: lighter, light, igniter, ignitor - label: 626\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1217, 3.0453], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5894, 0.4106], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.9828, 1.0175], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2544, 0.7456], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1217, 3.0453], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.5894, 0.4106], device='cuda:0')\n",
      "\tTPT model accuracy: 17/49 - predicted class 981: ballplayer, baseball player - tested: 49 / 7500\n",
      "\tMEMO model accuracy: 8/49 - predicted class 589: hand blower, blow dryer, blow drier, hair dryer, hair drier - tested: 49 / 7500\n",
      "\tSimple Ens accuracy (no back): 18/49 - predicted class 981: ballplayer, baseball player - tested: 49 / 7500\n",
      "\tEnsemble accuracy: 16/49 - predicted class 845: syringe - tested: 49 / 7500\n",
      "Testing on 1172 - name: garter snake, grass snake - label: 57\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7026, 1.0619], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2821, 0.7179], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.3592, 0.2018], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0442, 0.9558], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7026, 1.0619], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2821, 0.7179], device='cuda:0')\n",
      "\tTPT model accuracy: 17/50 - predicted class 428: barrow, garden cart, lawn cart, wheelbarrow - tested: 50 / 7500\n",
      "\tMEMO model accuracy: 8/50 - predicted class 428: barrow, garden cart, lawn cart, wheelbarrow - tested: 50 / 7500\n",
      "\tSimple Ens accuracy (no back): 19/50 - predicted class 57: garter snake, grass snake - tested: 50 / 7500\n",
      "\tEnsemble accuracy: 17/50 - predicted class 57: garter snake, grass snake - tested: 50 / 7500\n",
      "Testing on 807 - name: box turtle, box tortoise - label: 37\n",
      "\t\t[Ensemble] Entropies:  tensor([2.0328, 3.2997], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6188, 0.3812], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.0129, 1.7354], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6315, 0.3685], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.0328, 3.2997], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6188, 0.3812], device='cuda:0')\n",
      "\tTPT model accuracy: 17/51 - predicted class 125: hermit crab - tested: 51 / 7500\n",
      "\tMEMO model accuracy: 9/51 - predicted class 37: box turtle, box tortoise - tested: 51 / 7500\n",
      "\tSimple Ens accuracy (no back): 19/51 - predicted class 125: hermit crab - tested: 51 / 7500\n",
      "\tEnsemble accuracy: 17/51 - predicted class 125: hermit crab - tested: 51 / 7500\n",
      "Testing on 6277 - name: sandal - label: 774\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6170, 2.6976], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4272, 0.5728], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.1313, 0.1347], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1064, 0.8936], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.6170, 2.6976], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4272, 0.5728], device='cuda:0')\n",
      "\tTPT model accuracy: 17/52 - predicted class 797: sleeping bag - tested: 52 / 7500\n",
      "\tMEMO model accuracy: 9/52 - predicted class 880: unicycle, monocycle - tested: 52 / 7500\n",
      "\tSimple Ens accuracy (no back): 19/52 - predicted class 972: cliff, drop, drop-off - tested: 52 / 7500\n",
      "\tEnsemble accuracy: 17/52 - predicted class 972: cliff, drop, drop-off - tested: 52 / 7500\n",
      "Testing on 4760 - name: academic gown, academic robe, judge's robe - label: 400\n",
      "\t\t[Ensemble] Entropies:  tensor([1.2960, 0.7349], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3619, 0.6381], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1332e+00, 6.4295e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([3.0132e-04, 9.9970e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.2960, 0.7349], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3619, 0.6381], device='cuda:0')\n",
      "\tTPT model accuracy: 18/53 - predicted class 400: academic gown, academic robe, judge's robe - tested: 53 / 7500\n",
      "\tMEMO model accuracy: 9/53 - predicted class 862: torch - tested: 53 / 7500\n",
      "\tSimple Ens accuracy (no back): 20/53 - predicted class 400: academic gown, academic robe, judge's robe - tested: 53 / 7500\n",
      "\tEnsemble accuracy: 17/53 - predicted class 862: torch - tested: 53 / 7500\n",
      "Testing on 2816 - name: Rottweiler - label: 234\n",
      "\t\t[Ensemble] Entropies:  tensor([3.0745, 0.3839], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1110, 0.8890], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.9710, 0.0048], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0024, 0.9976], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.0745, 0.3839], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1110, 0.8890], device='cuda:0')\n",
      "\tTPT model accuracy: 18/54 - predicted class 254: pug, pug-dog - tested: 54 / 7500\n",
      "\tMEMO model accuracy: 10/54 - predicted class 234: Rottweiler - tested: 54 / 7500\n",
      "\tSimple Ens accuracy (no back): 21/54 - predicted class 234: Rottweiler - tested: 54 / 7500\n",
      "\tEnsemble accuracy: 18/54 - predicted class 234: Rottweiler - tested: 54 / 7500\n",
      "Testing on 4108 - name: monarch, monarch butterfly, milkweed butterfly, Danaus plexippus - label: 323\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8135, 0.6250], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1408, 0.8592], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4290e+00, 3.0823e-08], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([8.9888e-09, 1.0000e+00], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.8135, 0.6250], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1408, 0.8592], device='cuda:0')\n",
      "\tTPT model accuracy: 19/55 - predicted class 323: monarch, monarch butterfly, milkweed butterfly, Danaus plexippus - tested: 55 / 7500\n",
      "\tMEMO model accuracy: 11/55 - predicted class 323: monarch, monarch butterfly, milkweed butterfly, Danaus plexippus - tested: 55 / 7500\n",
      "\tSimple Ens accuracy (no back): 22/55 - predicted class 323: monarch, monarch butterfly, milkweed butterfly, Danaus plexippus - tested: 55 / 7500\n",
      "\tEnsemble accuracy: 19/55 - predicted class 323: monarch, monarch butterfly, milkweed butterfly, Danaus plexippus - tested: 55 / 7500\n",
      "Testing on 2090 - name: sea anemone, anemone - label: 108\n",
      "\t\t[Ensemble] Entropies:  tensor([3.3814, 1.1775], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2583, 0.7417], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.7820e+00, 1.1375e-05], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([6.3834e-06, 9.9999e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.3814, 1.1775], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.2583, 0.7417], device='cuda:0')\n",
      "\tTPT model accuracy: 19/56 - predicted class 107: jellyfish - tested: 56 / 7500\n",
      "\tMEMO model accuracy: 11/56 - predicted class 107: jellyfish - tested: 56 / 7500\n",
      "\tSimple Ens accuracy (no back): 22/56 - predicted class 107: jellyfish - tested: 56 / 7500\n",
      "\tEnsemble accuracy: 19/56 - predicted class 107: jellyfish - tested: 56 / 7500\n",
      "Testing on 580 - name: vulture - label: 23\n",
      "\t\t[Ensemble] Entropies:  tensor([0.9030, 1.8824], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6758, 0.3242], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.8831, 0.0216], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0113, 0.9887], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([0.9030, 1.8824], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.6758, 0.3242], device='cuda:0')\n",
      "\tTPT model accuracy: 19/57 - predicted class 143: oystercatcher, oyster catcher - tested: 57 / 7500\n",
      "\tMEMO model accuracy: 11/57 - predicted class 132: American egret, great white heron, Egretta albus - tested: 57 / 7500\n",
      "\tSimple Ens accuracy (no back): 22/57 - predicted class 143: oystercatcher, oyster catcher - tested: 57 / 7500\n",
      "\tEnsemble accuracy: 19/57 - predicted class 143: oystercatcher, oyster catcher - tested: 57 / 7500\n",
      "Testing on 722 - name: bullfrog, Rana catesbeiana - label: 30\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0392, 3.0658], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4315, 0.5685], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.2161, 0.3723], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1038, 0.8962], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0392, 3.0658], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4315, 0.5685], device='cuda:0')\n",
      "\tTPT model accuracy: 19/58 - predicted class 913: wreck - tested: 58 / 7500\n",
      "\tMEMO model accuracy: 11/58 - predicted class 701: parachute, chute - tested: 58 / 7500\n",
      "\tSimple Ens accuracy (no back): 22/58 - predicted class 701: parachute, chute - tested: 58 / 7500\n",
      "\tEnsemble accuracy: 19/58 - predicted class 980: volcano - tested: 58 / 7500\n",
      "Testing on 3342 - name: rhinoceros beetle - label: 306\n",
      "\t\t[Ensemble] Entropies:  tensor([1.7678, 0.1782], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0916, 0.9084], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.8357, 0.0048], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0026, 0.9974], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([1.7678, 0.1782], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0916, 0.9084], device='cuda:0')\n",
      "\tTPT model accuracy: 19/59 - predicted class 314: cockroach, roach - tested: 59 / 7500\n",
      "\tMEMO model accuracy: 11/59 - predicted class 314: cockroach, roach - tested: 59 / 7500\n",
      "\tSimple Ens accuracy (no back): 22/59 - predicted class 314: cockroach, roach - tested: 59 / 7500\n",
      "\tEnsemble accuracy: 19/59 - predicted class 314: cockroach, roach - tested: 59 / 7500\n",
      "Testing on 741 - name: bullfrog, Rana catesbeiana - label: 30\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7361, 1.7666], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3923, 0.6077], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.1772, 0.0025], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0012, 0.9988], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7361, 1.7666], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3923, 0.6077], device='cuda:0')\n",
      "\tTPT model accuracy: 19/60 - predicted class 71: scorpion - tested: 60 / 7500\n",
      "\tMEMO model accuracy: 12/60 - predicted class 30: bullfrog, Rana catesbeiana - tested: 60 / 7500\n",
      "\tSimple Ens accuracy (no back): 22/60 - predicted class 124: crayfish, crawfish, crawdad, crawdaddy - tested: 60 / 7500\n",
      "\tEnsemble accuracy: 19/60 - predicted class 124: crayfish, crawfish, crawdad, crawdaddy - tested: 60 / 7500\n",
      "Testing on 1175 - name: garter snake, grass snake - label: 57\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1828, 0.4221], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1171, 0.8829], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.7256e+00, 8.5788e-04], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([3.1465e-04, 9.9969e-01], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.1828, 0.4221], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.1171, 0.8829], device='cuda:0')\n",
      "\tTPT model accuracy: 19/61 - predicted class 456: bow - tested: 61 / 7500\n",
      "\tMEMO model accuracy: 13/61 - predicted class 57: garter snake, grass snake - tested: 61 / 7500\n",
      "\tSimple Ens accuracy (no back): 23/61 - predicted class 57: garter snake, grass snake - tested: 61 / 7500\n",
      "\tEnsemble accuracy: 20/61 - predicted class 57: garter snake, grass snake - tested: 61 / 7500\n",
      "Testing on 5624 - name: goblet - label: 572\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0261, 2.9388], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4219, 0.5781], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.1872, 0.0317], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0075, 0.9925], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.0261, 2.9388], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.4219, 0.5781], device='cuda:0')\n",
      "\tTPT model accuracy: 19/62 - predicted class 971: bubble - tested: 62 / 7500\n",
      "\tMEMO model accuracy: 13/62 - predicted class 641: maraca - tested: 62 / 7500\n",
      "\tSimple Ens accuracy (no back): 23/62 - predicted class 641: maraca - tested: 62 / 7500\n",
      "\tEnsemble accuracy: 20/62 - predicted class 971: bubble - tested: 62 / 7500\n",
      "Testing on 3802 - name: cockroach, roach - label: 314\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8661, 0.1343], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0448, 0.9552], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.4320, 0.0463], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0187, 0.9813], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([2.8661, 0.1343], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0448, 0.9552], device='cuda:0')\n",
      "\tTPT model accuracy: 20/63 - predicted class 314: cockroach, roach - tested: 63 / 7500\n",
      "\tMEMO model accuracy: 14/63 - predicted class 314: cockroach, roach - tested: 63 / 7500\n",
      "\tSimple Ens accuracy (no back): 24/63 - predicted class 314: cockroach, roach - tested: 63 / 7500\n",
      "\tEnsemble accuracy: 21/63 - predicted class 314: cockroach, roach - tested: 63 / 7500\n",
      "Testing on 2288 - name: snail - label: 113\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4926, 1.7404], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3326, 0.6674], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([4.2705, 0.0611], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.0141, 0.9859], device='cuda:0')\n",
      "\t\t[Ensemble] Entropies:  tensor([3.4926, 1.7404], device='cuda:0')\n",
      "\t\t[Ensemble] Scales:  tensor([0.3326, 0.6674], device='cuda:0')\n",
      "\tTPT model accuracy: 20/64 - predicted class 313: walking stick, walkingstick, stick insect - tested: 64 / 7500\n",
      "\tMEMO model accuracy: 14/64 - predicted class 987: corn - tested: 64 / 7500\n",
      "\tSimple Ens accuracy (no back): 24/64 - predicted class 313: walking stick, walkingstick, stick insect - tested: 64 / 7500\n",
      "\tEnsemble accuracy: 21/64 - predicted class 988: acorn - tested: 64 / 7500\n",
      "Testing on 6669 - name: tank, army tank, armored combat vehicle, armoured combat vehicle - label: 847\n"
     ]
    }
   ],
   "source": [
    "tpt_model, tpt_data, mapping = TPT(TPT_device, naug=naug, A=imageNetA)\n",
    "    \n",
    "memo_model, memo_data = memo(MEMO_device, naug=naug, A=imageNetA)\n",
    "\n",
    "if (imageNetA):\n",
    "    print(\"Testing on ImageNet-A\")\n",
    "else:\n",
    "    print(\"Testing on ImageNet-V2\")\n",
    "\n",
    "test(tpt_model, memo_model, \n",
    "     tpt_data, mapping, memo_data, \n",
    "     device, niter, top, no_backwards, testSingleModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
